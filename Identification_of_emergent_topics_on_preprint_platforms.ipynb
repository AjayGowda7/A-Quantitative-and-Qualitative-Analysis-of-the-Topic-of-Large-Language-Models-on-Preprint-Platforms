{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adafec16-c81a-4610-a6f4-90ebfc3c0c9f",
   "metadata": {},
   "source": [
    "# Imports and read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94219f31-8b55-4d0b-81c1-92a373d3f682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ajaylakkegowda/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ajaylakkegowda/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import dedupe\n",
    "from typing import Union\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from thefuzz import fuzz\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import plotly_express as px\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "pio.renderers.default = \"iframe\"\n",
    "\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_core_components as dcc\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords, strip_tags, strip_punctuation, preprocess_string, STOPWORDS\n",
    "custom_text_filters = [lambda x: x.lower(),\n",
    "                       lambda x: x.replace('e.g.', ''),\n",
    "                       lambda x: x.replace('i.e', ''),\n",
    "                       lambda x: x.replace('paper', ''),\n",
    "                       lambda x: x.replace('real', ''),\n",
    "                       lambda x: x.replace('world', ''),\n",
    "                       lambda x: x.replace('https', ''),\n",
    "                       lambda x: x.replace('github', ''),\n",
    "                       lambda x: x.replace('com', ''),\n",
    "                       lambda x: x.replace('state', ''),\n",
    "                       lambda x: x.replace('art', ''),\n",
    "                       lambda x: x.replace('ieee', ''),\n",
    "                       strip_tags,strip_punctuation,remove_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203d1729-d861-42a9-96e3-ef0bfae0d97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2318918it [01:57, 19812.87it/s] \n"
     ]
    }
   ],
   "source": [
    "category_prefixes = ['stat.','cs.']\n",
    "papers = []\n",
    "with open('arxiv-metadata-oai-snapshot.json', 'r') as file_data:\n",
    "    for data in tqdm(file_data):\n",
    "        papers.append(json.loads(data))\n",
    "arxiv_papers = pd.DataFrame(papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac6f188-6dd7-429d-972d-30d5178cce63",
   "metadata": {},
   "source": [
    "# Data Preprocessing for arxiv papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b392afda-01a9-43b9-9685-e42a9da25e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_papers.drop(['comments', 'journal-ref', 'report-no', 'license'], inplace=True, axis = 1)\n",
    "arxiv_papers = arxiv_papers[arxiv_papers['categories'].apply(lambda x: any(x.startswith(prefix) for prefix in category_prefixes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e882278-1b59-4b3f-8cdc-3acea6dde6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0704.0047</td>\n",
       "      <td>Igor Grabec</td>\n",
       "      <td>T. Kosel and I. Grabec</td>\n",
       "      <td>Intelligent location of simultaneously active ...</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.NE cs.AI</td>\n",
       "      <td>The intelligent acoustic emission locator is...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Apr 2007...</td>\n",
       "      <td>2009-09-29</td>\n",
       "      <td>[[Kosel, T., ], [Grabec, I., ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0704.0050</td>\n",
       "      <td>Igor Grabec</td>\n",
       "      <td>T. Kosel and I. Grabec</td>\n",
       "      <td>Intelligent location of simultaneously active ...</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.NE cs.AI</td>\n",
       "      <td>Part I describes an intelligent acoustic emi...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Apr 2007...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[[Kosel, T., ], [Grabec, I., ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0704.0062</td>\n",
       "      <td>Tom\\'a\\v{s} Vina\\v{r}</td>\n",
       "      <td>Rastislav \\v{S}r\\'amek, Bro\\v{n}a Brejov\\'a, T...</td>\n",
       "      <td>On-line Viterbi Algorithm and Its Relationship...</td>\n",
       "      <td>10.1007/978-3-540-74126-8_23</td>\n",
       "      <td>cs.DS</td>\n",
       "      <td>In this paper, we introduce the on-line Vite...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
       "      <td>2010-01-25</td>\n",
       "      <td>[[Šrámek, Rastislav, ], [Brejová, Broňa, ], [V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0704.0090</td>\n",
       "      <td>Lester Ingber</td>\n",
       "      <td>Lester Ingber</td>\n",
       "      <td>Real Options for Project Schedules (ROPS)</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.CE cond-mat.stat-mech cs.MS cs.NA physics.d...</td>\n",
       "      <td>Real Options for Project Schedules (ROPS) ha...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Apr 2007...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[[Ingber, Lester, ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0704.0098</td>\n",
       "      <td>Jack Raymond</td>\n",
       "      <td>Jack Raymond, David Saad</td>\n",
       "      <td>Sparsely-spread CDMA - a statistical mechanics...</td>\n",
       "      <td>10.1088/1751-8113/40/41/004</td>\n",
       "      <td>cs.IT math.IT</td>\n",
       "      <td>Sparse Code Division Multiple Access (CDMA),...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Apr 2007...</td>\n",
       "      <td>2009-11-13</td>\n",
       "      <td>[[Raymond, Jack, ], [Saad, David, ]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id              submitter  \\\n",
       "46  0704.0047            Igor Grabec   \n",
       "49  0704.0050            Igor Grabec   \n",
       "61  0704.0062  Tom\\'a\\v{s} Vina\\v{r}   \n",
       "89  0704.0090          Lester Ingber   \n",
       "97  0704.0098           Jack Raymond   \n",
       "\n",
       "                                              authors  \\\n",
       "46                             T. Kosel and I. Grabec   \n",
       "49                             T. Kosel and I. Grabec   \n",
       "61  Rastislav \\v{S}r\\'amek, Bro\\v{n}a Brejov\\'a, T...   \n",
       "89                                      Lester Ingber   \n",
       "97                           Jack Raymond, David Saad   \n",
       "\n",
       "                                                title  \\\n",
       "46  Intelligent location of simultaneously active ...   \n",
       "49  Intelligent location of simultaneously active ...   \n",
       "61  On-line Viterbi Algorithm and Its Relationship...   \n",
       "89          Real Options for Project Schedules (ROPS)   \n",
       "97  Sparsely-spread CDMA - a statistical mechanics...   \n",
       "\n",
       "                             doi  \\\n",
       "46                          None   \n",
       "49                          None   \n",
       "61  10.1007/978-3-540-74126-8_23   \n",
       "89                          None   \n",
       "97   10.1088/1751-8113/40/41/004   \n",
       "\n",
       "                                           categories  \\\n",
       "46                                        cs.NE cs.AI   \n",
       "49                                        cs.NE cs.AI   \n",
       "61                                              cs.DS   \n",
       "89  cs.CE cond-mat.stat-mech cs.MS cs.NA physics.d...   \n",
       "97                                      cs.IT math.IT   \n",
       "\n",
       "                                             abstract  \\\n",
       "46    The intelligent acoustic emission locator is...   \n",
       "49    Part I describes an intelligent acoustic emi...   \n",
       "61    In this paper, we introduce the on-line Vite...   \n",
       "89    Real Options for Project Schedules (ROPS) ha...   \n",
       "97    Sparse Code Division Multiple Access (CDMA),...   \n",
       "\n",
       "                                             versions update_date  \\\n",
       "46  [{'version': 'v1', 'created': 'Sun, 1 Apr 2007...  2009-09-29   \n",
       "49  [{'version': 'v1', 'created': 'Sun, 1 Apr 2007...  2007-05-23   \n",
       "61  [{'version': 'v1', 'created': 'Sat, 31 Mar 200...  2010-01-25   \n",
       "89  [{'version': 'v1', 'created': 'Sun, 1 Apr 2007...  2007-05-23   \n",
       "97  [{'version': 'v1', 'created': 'Sun, 1 Apr 2007...  2009-11-13   \n",
       "\n",
       "                                       authors_parsed  \n",
       "46                    [[Kosel, T., ], [Grabec, I., ]]  \n",
       "49                    [[Kosel, T., ], [Grabec, I., ]]  \n",
       "61  [[Šrámek, Rastislav, ], [Brejová, Broňa, ], [V...  \n",
       "89                               [[Ingber, Lester, ]]  \n",
       "97               [[Raymond, Jack, ], [Saad, David, ]]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cac127f3-c171-4a41-b31c-d292ff32a6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 486484 entries, 46 to 2072139\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   id              486484 non-null  object\n",
      " 1   submitter       486356 non-null  object\n",
      " 2   authors         486484 non-null  object\n",
      " 3   title           486484 non-null  object\n",
      " 4   doi             82245 non-null   object\n",
      " 5   categories      486484 non-null  object\n",
      " 6   abstract        486484 non-null  object\n",
      " 7   versions        486484 non-null  object\n",
      " 8   update_date     486484 non-null  object\n",
      " 9   authors_parsed  486484 non-null  object\n",
      "dtypes: object(10)\n",
      "memory usage: 40.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#DataFrame summary\n",
    "arxiv_papers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7292aee1-6e45-4135-b408-6fe300d1e511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "submitter            128\n",
       "authors                0\n",
       "title                  0\n",
       "doi               404239\n",
       "categories             0\n",
       "abstract               0\n",
       "versions               0\n",
       "update_date            0\n",
       "authors_parsed         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of missing values per column\n",
    "arxiv_papers.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410ecf43-4dd1-4ed9-8b82-dd30ab5856cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "arxiv_papers.drop_duplicates(subset=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddf472c2-156a-40ad-bb5d-ac063a27474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "arxiv_papers.dropna(subset=['title', 'abstract', 'update_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0da5a109-ad81-4c32-9f6d-b5bfbeab37de",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_papers.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f008cbb9-4498-4aad-b927-744b81fa4016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "submitter            128\n",
       "authors                0\n",
       "title                  0\n",
       "doi               404239\n",
       "categories             0\n",
       "abstract               0\n",
       "versions               0\n",
       "update_date            0\n",
       "authors_parsed         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of missing values per column\n",
    "arxiv_papers.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "895835ff-13f5-4b8a-9402-f9f1da937c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 486484 entries, 0 to 486483\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   id              486484 non-null  object\n",
      " 1   submitter       486356 non-null  object\n",
      " 2   authors         486484 non-null  object\n",
      " 3   title           486484 non-null  object\n",
      " 4   doi             82245 non-null   object\n",
      " 5   categories      486484 non-null  object\n",
      " 6   abstract        486484 non-null  object\n",
      " 7   versions        486484 non-null  object\n",
      " 8   update_date     486484 non-null  object\n",
      " 9   authors_parsed  486484 non-null  object\n",
      "dtypes: object(10)\n",
      "memory usage: 37.1+ MB\n"
     ]
    }
   ],
   "source": [
    "arxiv_papers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97a0016b-1821-48c7-96fa-8f55d87d7d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'version': 'v1', 'created': 'Sun, 1 Apr 2007 13:06:50 GMT'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_papers.versions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "583a6812-2ab5-4e85-a2d4-91d7316bfff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_papers['date'] = arxiv_papers['versions'].str[0].str.get('created')\n",
    "arxiv_papers['date'] = pd.to_datetime(arxiv_papers.date, infer_datetime_format=True)\n",
    "arxiv_papers['year'] = arxiv_papers['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f28e5abe-5e54-4743-98d6-9c6d464e158d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0047</td>\n",
       "      <td>Igor Grabec</td>\n",
       "      <td>T. Kosel and I. Grabec</td>\n",
       "      <td>Intelligent location of simultaneously active ...</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.NE cs.AI</td>\n",
       "      <td>The intelligent acoustic emission locator is...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Apr 2007...</td>\n",
       "      <td>2009-09-29</td>\n",
       "      <td>[[Kosel, T., ], [Grabec, I., ]]</td>\n",
       "      <td>2007-04-01 13:06:50</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0050</td>\n",
       "      <td>Igor Grabec</td>\n",
       "      <td>T. Kosel and I. Grabec</td>\n",
       "      <td>Intelligent location of simultaneously active ...</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.NE cs.AI</td>\n",
       "      <td>Part I describes an intelligent acoustic emi...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Apr 2007...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[[Kosel, T., ], [Grabec, I., ]]</td>\n",
       "      <td>2007-04-01 18:53:13</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0062</td>\n",
       "      <td>Tom\\'a\\v{s} Vina\\v{r}</td>\n",
       "      <td>Rastislav \\v{S}r\\'amek, Bro\\v{n}a Brejov\\'a, T...</td>\n",
       "      <td>On-line Viterbi Algorithm and Its Relationship...</td>\n",
       "      <td>10.1007/978-3-540-74126-8_23</td>\n",
       "      <td>cs.DS</td>\n",
       "      <td>In this paper, we introduce the on-line Vite...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
       "      <td>2010-01-25</td>\n",
       "      <td>[[Šrámek, Rastislav, ], [Brejová, Broňa, ], [V...</td>\n",
       "      <td>2007-03-31 23:52:33</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0090</td>\n",
       "      <td>Lester Ingber</td>\n",
       "      <td>Lester Ingber</td>\n",
       "      <td>Real Options for Project Schedules (ROPS)</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.CE cond-mat.stat-mech cs.MS cs.NA physics.d...</td>\n",
       "      <td>Real Options for Project Schedules (ROPS) ha...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Apr 2007...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[[Ingber, Lester, ]]</td>\n",
       "      <td>2007-04-01 14:35:40</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0098</td>\n",
       "      <td>Jack Raymond</td>\n",
       "      <td>Jack Raymond, David Saad</td>\n",
       "      <td>Sparsely-spread CDMA - a statistical mechanics...</td>\n",
       "      <td>10.1088/1751-8113/40/41/004</td>\n",
       "      <td>cs.IT math.IT</td>\n",
       "      <td>Sparse Code Division Multiple Access (CDMA),...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Apr 2007...</td>\n",
       "      <td>2009-11-13</td>\n",
       "      <td>[[Raymond, Jack, ], [Saad, David, ]]</td>\n",
       "      <td>2007-04-01 18:27:26</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id              submitter  \\\n",
       "0  0704.0047            Igor Grabec   \n",
       "1  0704.0050            Igor Grabec   \n",
       "2  0704.0062  Tom\\'a\\v{s} Vina\\v{r}   \n",
       "3  0704.0090          Lester Ingber   \n",
       "4  0704.0098           Jack Raymond   \n",
       "\n",
       "                                             authors  \\\n",
       "0                             T. Kosel and I. Grabec   \n",
       "1                             T. Kosel and I. Grabec   \n",
       "2  Rastislav \\v{S}r\\'amek, Bro\\v{n}a Brejov\\'a, T...   \n",
       "3                                      Lester Ingber   \n",
       "4                           Jack Raymond, David Saad   \n",
       "\n",
       "                                               title  \\\n",
       "0  Intelligent location of simultaneously active ...   \n",
       "1  Intelligent location of simultaneously active ...   \n",
       "2  On-line Viterbi Algorithm and Its Relationship...   \n",
       "3          Real Options for Project Schedules (ROPS)   \n",
       "4  Sparsely-spread CDMA - a statistical mechanics...   \n",
       "\n",
       "                            doi  \\\n",
       "0                          None   \n",
       "1                          None   \n",
       "2  10.1007/978-3-540-74126-8_23   \n",
       "3                          None   \n",
       "4   10.1088/1751-8113/40/41/004   \n",
       "\n",
       "                                          categories  \\\n",
       "0                                        cs.NE cs.AI   \n",
       "1                                        cs.NE cs.AI   \n",
       "2                                              cs.DS   \n",
       "3  cs.CE cond-mat.stat-mech cs.MS cs.NA physics.d...   \n",
       "4                                      cs.IT math.IT   \n",
       "\n",
       "                                            abstract  \\\n",
       "0    The intelligent acoustic emission locator is...   \n",
       "1    Part I describes an intelligent acoustic emi...   \n",
       "2    In this paper, we introduce the on-line Vite...   \n",
       "3    Real Options for Project Schedules (ROPS) ha...   \n",
       "4    Sparse Code Division Multiple Access (CDMA),...   \n",
       "\n",
       "                                            versions update_date  \\\n",
       "0  [{'version': 'v1', 'created': 'Sun, 1 Apr 2007...  2009-09-29   \n",
       "1  [{'version': 'v1', 'created': 'Sun, 1 Apr 2007...  2007-05-23   \n",
       "2  [{'version': 'v1', 'created': 'Sat, 31 Mar 200...  2010-01-25   \n",
       "3  [{'version': 'v1', 'created': 'Sun, 1 Apr 2007...  2007-05-23   \n",
       "4  [{'version': 'v1', 'created': 'Sun, 1 Apr 2007...  2009-11-13   \n",
       "\n",
       "                                      authors_parsed                date  year  \n",
       "0                    [[Kosel, T., ], [Grabec, I., ]] 2007-04-01 13:06:50  2007  \n",
       "1                    [[Kosel, T., ], [Grabec, I., ]] 2007-04-01 18:53:13  2007  \n",
       "2  [[Šrámek, Rastislav, ], [Brejová, Broňa, ], [V... 2007-03-31 23:52:33  2007  \n",
       "3                               [[Ingber, Lester, ]] 2007-04-01 14:35:40  2007  \n",
       "4               [[Raymond, Jack, ], [Saad, David, ]] 2007-04-01 18:27:26  2007  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffffbda6-e1ef-41dc-9fac-9fabb9501178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest creation date: 1990-01-01 00:00:00\n",
      "Latest creation date: 2023-08-31 17:59:46\n"
     ]
    }
   ],
   "source": [
    "arxiv_papers.sort_values(by='date', inplace=True)\n",
    "# Find and display the earliest and latest creation dates in the 'papers' DataFrame\n",
    "earliest_date = arxiv_papers['date'].iloc[0]\n",
    "latest_date = arxiv_papers['date'].iloc[-1]\n",
    "print(f\"Earliest creation date: {earliest_date}\\nLatest creation date: {latest_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f900d-3bcb-4e44-bf83-20c299e8f2cb",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Socpus Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9f819a7-4189-410f-b0b9-e117e63e53b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scopus_papers = pd.read_excel('scopus.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84dc9115-8906-4e69-a42b-c814f75f0a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19539 entries, 0 to 19538\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   authors    19053 non-null  object\n",
      " 1   title      19539 non-null  object\n",
      " 2   year       19539 non-null  int64 \n",
      " 3   doi        14347 non-null  object\n",
      " 4   abstract   19539 non-null  object\n",
      " 5   submitter  17566 non-null  object\n",
      " 6   id         19539 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#DataFrame summary\n",
    "scopus_papers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "652968a9-78fd-4f4b-993e-d0a767d48879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authors       486\n",
       "title           0\n",
       "year            0\n",
       "doi          5192\n",
       "abstract        0\n",
       "submitter    1973\n",
       "id              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of missing values per column\n",
    "scopus_papers.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1bc75b2-5bdd-4607-9577-20615982020a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract</th>\n",
       "      <th>submitter</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kaur G.; Sharma A.</td>\n",
       "      <td>HAS: Hybrid Analysis of Sentiments for the per...</td>\n",
       "      <td>2023</td>\n",
       "      <td>10.1007/s12652-022-03748-6</td>\n",
       "      <td>The reviews posted online by the end-users can...</td>\n",
       "      <td>Springer Science and Business Media Deutschlan...</td>\n",
       "      <td>2-s2.0-85124830704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hu S.; Zhang H.; Zhang W.</td>\n",
       "      <td>Domain Knowledge Graph Question Answering Base...</td>\n",
       "      <td>2023</td>\n",
       "      <td>10.3390/app13158838</td>\n",
       "      <td>Information retrieval-based question answering...</td>\n",
       "      <td>Multidisciplinary Digital Publishing Institute...</td>\n",
       "      <td>2-s2.0-85167883197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lai Z.; Wei K.; Fu Y.; H√§rtel P.; Heide F.</td>\n",
       "      <td>Œ¥-Prox: Differentiable Proximal Algorithm Mod...</td>\n",
       "      <td>2023</td>\n",
       "      <td>10.1145/3592144</td>\n",
       "      <td>Tasks across diverse application domains can b...</td>\n",
       "      <td>Association for Computing Machinery</td>\n",
       "      <td>2-s2.0-85167400308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wang S.; Zhang Y.; Shi W.; Zhang G.; Zhang J.;...</td>\n",
       "      <td>A large dataset of semantic ratings and its co...</td>\n",
       "      <td>2023</td>\n",
       "      <td>10.1038/s41597-023-01995-6</td>\n",
       "      <td>Evidence from psychology and cognitive neurosc...</td>\n",
       "      <td>Nature Research</td>\n",
       "      <td>2-s2.0-85148814027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Li F.; Wang Y.; Jiang J.; Zhang H.; Wang X.; C...</td>\n",
       "      <td>Heterogeneous acceleration algorithms for shal...</td>\n",
       "      <td>2023</td>\n",
       "      <td>10.1016/j.future.2023.04.021</td>\n",
       "      <td>The physical process of atmospheric cumulus co...</td>\n",
       "      <td>Elsevier B.V.</td>\n",
       "      <td>2-s2.0-85157998857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             authors  \\\n",
       "0                                 Kaur G.; Sharma A.   \n",
       "1                          Hu S.; Zhang H.; Zhang W.   \n",
       "2        Lai Z.; Wei K.; Fu Y.; H√§rtel P.; Heide F.   \n",
       "3  Wang S.; Zhang Y.; Shi W.; Zhang G.; Zhang J.;...   \n",
       "4  Li F.; Wang Y.; Jiang J.; Zhang H.; Wang X.; C...   \n",
       "\n",
       "                                               title  year  \\\n",
       "0  HAS: Hybrid Analysis of Sentiments for the per...  2023   \n",
       "1  Domain Knowledge Graph Question Answering Base...  2023   \n",
       "2  Œ¥-Prox: Differentiable Proximal Algorithm Mod...  2023   \n",
       "3  A large dataset of semantic ratings and its co...  2023   \n",
       "4  Heterogeneous acceleration algorithms for shal...  2023   \n",
       "\n",
       "                            doi  \\\n",
       "0    10.1007/s12652-022-03748-6   \n",
       "1           10.3390/app13158838   \n",
       "2               10.1145/3592144   \n",
       "3    10.1038/s41597-023-01995-6   \n",
       "4  10.1016/j.future.2023.04.021   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  The reviews posted online by the end-users can...   \n",
       "1  Information retrieval-based question answering...   \n",
       "2  Tasks across diverse application domains can b...   \n",
       "3  Evidence from psychology and cognitive neurosc...   \n",
       "4  The physical process of atmospheric cumulus co...   \n",
       "\n",
       "                                           submitter                  id  \n",
       "0  Springer Science and Business Media Deutschlan...  2-s2.0-85124830704  \n",
       "1  Multidisciplinary Digital Publishing Institute...  2-s2.0-85167883197  \n",
       "2                Association for Computing Machinery  2-s2.0-85167400308  \n",
       "3                                    Nature Research  2-s2.0-85148814027  \n",
       "4                                      Elsevier B.V.  2-s2.0-85157998857  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scopus_papers.reset_index(drop=True, inplace=True)\n",
    "scopus_papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59b0a62-cf47-4fe8-8cc0-39f08369e0b9",
   "metadata": {},
   "source": [
    "# Data Preprocessing for DBLP papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e5e1f66-26a0-4ca0-be08-bd49b7be918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_papers = pd.read_excel('dblp.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "275d33d2-124d-4760-a855-512ea7f63e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1241 entries, 0 to 1240\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         1241 non-null   int64 \n",
      " 1   authors    1240 non-null   object\n",
      " 2   title      1241 non-null   object\n",
      " 3   abstract   1241 non-null   object\n",
      " 4   submitter  1238 non-null   object\n",
      " 5   year       1241 non-null   int64 \n",
      " 6   doi        1131 non-null   object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 68.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#DataFrame summary\n",
    "dblp_papers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f1801ba-e96d-4701-a57a-1bbc7e8ede5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "authors        1\n",
       "title          0\n",
       "abstract       0\n",
       "submitter      3\n",
       "year           0\n",
       "doi          110\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of missing values per column\n",
    "dblp_papers.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b0e53b9-28de-484e-ab3b-90c686990e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>submitter</th>\n",
       "      <th>year</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>209840</td>\n",
       "      <td>Yinlin Deng;Chunqiu Steven Xia;Haoran Peng;Che...</td>\n",
       "      <td>Large Language Models Are Zero-Shot Fuzzers: F...</td>\n",
       "      <td>Large Language Models Are Zero-Shot Fuzzers: F...</td>\n",
       "      <td>ISSTA</td>\n",
       "      <td>2023</td>\n",
       "      <td>10.1145/3597926.3598067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151722</td>\n",
       "      <td>Sherzod Hakimov;David Schlangen</td>\n",
       "      <td>Images in Language Space: Exploring the Suitab...</td>\n",
       "      <td>Images in Language Space: Exploring the Suitab...</td>\n",
       "      <td>ACL</td>\n",
       "      <td>2023</td>\n",
       "      <td>10.18653/V1/2023.FINDINGS-ACL.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>257780</td>\n",
       "      <td>Michael Wornow;Yizhe Xu;Rahul Thapa;Birju S. P...</td>\n",
       "      <td>The Shaky Foundations of Clinical Foundation M...</td>\n",
       "      <td>The Shaky Foundations of Clinical Foundation M...</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>2023</td>\n",
       "      <td>10.48550/ARXIV.2303.12961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>273908</td>\n",
       "      <td>Yueting Yang;Xintong Zhang;Wenjuan Han</td>\n",
       "      <td>Enhance Reasoning Ability of Visual-Language M...</td>\n",
       "      <td>Enhance Reasoning Ability of Visual-Language M...</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>2023</td>\n",
       "      <td>10.48550/ARXIV.2305.13267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>274189</td>\n",
       "      <td>Sherzod Hakimov;David Schlangen</td>\n",
       "      <td>Images in Language Space: Exploring the Suitab...</td>\n",
       "      <td>Images in Language Space: Exploring the Suitab...</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>2023</td>\n",
       "      <td>10.48550/ARXIV.2305.13782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                            authors  \\\n",
       "0  209840  Yinlin Deng;Chunqiu Steven Xia;Haoran Peng;Che...   \n",
       "1  151722                    Sherzod Hakimov;David Schlangen   \n",
       "2  257780  Michael Wornow;Yizhe Xu;Rahul Thapa;Birju S. P...   \n",
       "3  273908             Yueting Yang;Xintong Zhang;Wenjuan Han   \n",
       "4  274189                    Sherzod Hakimov;David Schlangen   \n",
       "\n",
       "                                               title  \\\n",
       "0  Large Language Models Are Zero-Shot Fuzzers: F...   \n",
       "1  Images in Language Space: Exploring the Suitab...   \n",
       "2  The Shaky Foundations of Clinical Foundation M...   \n",
       "3  Enhance Reasoning Ability of Visual-Language M...   \n",
       "4  Images in Language Space: Exploring the Suitab...   \n",
       "\n",
       "                                            abstract submitter  year  \\\n",
       "0  Large Language Models Are Zero-Shot Fuzzers: F...     ISSTA  2023   \n",
       "1  Images in Language Space: Exploring the Suitab...       ACL  2023   \n",
       "2  The Shaky Foundations of Clinical Foundation M...      CoRR  2023   \n",
       "3  Enhance Reasoning Ability of Visual-Language M...      CoRR  2023   \n",
       "4  Images in Language Space: Exploring the Suitab...      CoRR  2023   \n",
       "\n",
       "                                 doi  \n",
       "0            10.1145/3597926.3598067  \n",
       "1  10.18653/V1/2023.FINDINGS-ACL.894  \n",
       "2          10.48550/ARXIV.2303.12961  \n",
       "3          10.48550/ARXIV.2305.13267  \n",
       "4          10.48550/ARXIV.2305.13782  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dblp_papers.reset_index(drop=True, inplace=True)\n",
    "dblp_papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f01a1e-1c9e-4348-b7eb-edb10935d03e",
   "metadata": {},
   "source": [
    "# Data Preprocessing for all papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a649a08-9a24-4665-9ee0-e097d576d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = pd.concat([arxiv_papers, scopus_papers, dblp_papers], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65ecf2ff-7068-4142-80e1-ecc629e37f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>507259</th>\n",
       "      <td>776950</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>Shailja Thakur;Baleegh Ahmad;Zhenxing Fan;Hamm...</td>\n",
       "      <td>Benchmarking Large Language Models for Automat...</td>\n",
       "      <td>10.48550/ARXIV.2212.11140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benchmarking Large Language Models for Automat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507260</th>\n",
       "      <td>777308</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>Byung-Doh Oh;William Schuler</td>\n",
       "      <td>Why Does Surprisal From Larger Transformer-Bas...</td>\n",
       "      <td>10.48550/ARXIV.2212.12131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Why Does Surprisal From Larger Transformer-Bas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507261</th>\n",
       "      <td>777650</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>Karan Singhal;Shekoofeh Azizi;Tao Tu;S. Sara M...</td>\n",
       "      <td>Large Language Models Encode Clinical Knowledge.</td>\n",
       "      <td>10.48550/ARXIV.2212.13138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Large Language Models Encode Clinical Knowledge.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507262</th>\n",
       "      <td>777989</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>Ashley Liew;Klaus Mueller</td>\n",
       "      <td>Using Large Language Models to Generate Engagi...</td>\n",
       "      <td>10.48550/ARXIV.2212.14047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Using Large Language Models to Generate Engagi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507263</th>\n",
       "      <td>778319</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>Yinlin Deng;Chunqiu Steven Xia;Haoran Peng;Che...</td>\n",
       "      <td>Fuzzing Deep-Learning Libraries via Large Lang...</td>\n",
       "      <td>10.48550/ARXIV.2212.14834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fuzzing Deep-Learning Libraries via Large Lang...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id submitter                                            authors  \\\n",
       "507259  776950      CoRR  Shailja Thakur;Baleegh Ahmad;Zhenxing Fan;Hamm...   \n",
       "507260  777308      CoRR                       Byung-Doh Oh;William Schuler   \n",
       "507261  777650      CoRR  Karan Singhal;Shekoofeh Azizi;Tao Tu;S. Sara M...   \n",
       "507262  777989      CoRR                          Ashley Liew;Klaus Mueller   \n",
       "507263  778319      CoRR  Yinlin Deng;Chunqiu Steven Xia;Haoran Peng;Che...   \n",
       "\n",
       "                                                    title  \\\n",
       "507259  Benchmarking Large Language Models for Automat...   \n",
       "507260  Why Does Surprisal From Larger Transformer-Bas...   \n",
       "507261   Large Language Models Encode Clinical Knowledge.   \n",
       "507262  Using Large Language Models to Generate Engagi...   \n",
       "507263  Fuzzing Deep-Learning Libraries via Large Lang...   \n",
       "\n",
       "                              doi categories  \\\n",
       "507259  10.48550/ARXIV.2212.11140        NaN   \n",
       "507260  10.48550/ARXIV.2212.12131        NaN   \n",
       "507261  10.48550/ARXIV.2212.13138        NaN   \n",
       "507262  10.48550/ARXIV.2212.14047        NaN   \n",
       "507263  10.48550/ARXIV.2212.14834        NaN   \n",
       "\n",
       "                                                 abstract versions  \\\n",
       "507259  Benchmarking Large Language Models for Automat...      NaN   \n",
       "507260  Why Does Surprisal From Larger Transformer-Bas...      NaN   \n",
       "507261   Large Language Models Encode Clinical Knowledge.      NaN   \n",
       "507262  Using Large Language Models to Generate Engagi...      NaN   \n",
       "507263  Fuzzing Deep-Learning Libraries via Large Lang...      NaN   \n",
       "\n",
       "       update_date authors_parsed date  year  \n",
       "507259         NaN            NaN  NaT  2022  \n",
       "507260         NaN            NaN  NaT  2022  \n",
       "507261         NaN            NaN  NaT  2022  \n",
       "507262         NaN            NaN  NaT  2022  \n",
       "507263         NaN            NaN  NaT  2022  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f463dba5-bf5c-43ed-a748-5349a3d23f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "507264"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87a7fd98-9a5c-472d-af2e-623e25b43dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 507264/507264 [01:36<00:00, 5243.98it/s]\n",
      "100%|████████████████████████████████| 507264/507264 [00:37<00:00, 13422.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>507259</th>\n",
       "      <td>776950</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>Shailja Thakur;Baleegh Ahmad;Zhenxing Fan;Hamm...</td>\n",
       "      <td>Benchmarking Large Language Models for Automat...</td>\n",
       "      <td>10.48550/ARXIV.2212.11140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benchmarking Large Language Models for Automat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Baleegh Ahmad], [Shailja Thakur], [Benjamin ...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507260</th>\n",
       "      <td>777308</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>Byung-Doh Oh;William Schuler</td>\n",
       "      <td>Why Does Surprisal From Larger Transformer-Bas...</td>\n",
       "      <td>10.48550/ARXIV.2212.12131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Why Does Surprisal From Larger Transformer-Bas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Byung-Doh Oh], [William Schuler]]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507261</th>\n",
       "      <td>777650</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>Karan Singhal;Shekoofeh Azizi;Tao Tu;S. Sara M...</td>\n",
       "      <td>Large Language Models Encode Clinical Knowledge.</td>\n",
       "      <td>10.48550/ARXIV.2212.13138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Large Language Models Encode Clinical Knowledge.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Hyung Won Chung], [Tao Tu], [Nathan Scales],...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507262</th>\n",
       "      <td>777989</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>Ashley Liew;Klaus Mueller</td>\n",
       "      <td>Using Large Language Models to Generate Engagi...</td>\n",
       "      <td>10.48550/ARXIV.2212.14047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Using Large Language Models to Generate Engagi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Klaus Mueller], [Ashley Liew]]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507263</th>\n",
       "      <td>778319</td>\n",
       "      <td>CoRR</td>\n",
       "      <td>Yinlin Deng;Chunqiu Steven Xia;Haoran Peng;Che...</td>\n",
       "      <td>Fuzzing Deep-Learning Libraries via Large Lang...</td>\n",
       "      <td>10.48550/ARXIV.2212.14834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fuzzing Deep-Learning Libraries via Large Lang...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Yinlin Deng], [Haoran Peng], [Chenyuan Yang]...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id submitter                                            authors  \\\n",
       "507259  776950      CoRR  Shailja Thakur;Baleegh Ahmad;Zhenxing Fan;Hamm...   \n",
       "507260  777308      CoRR                       Byung-Doh Oh;William Schuler   \n",
       "507261  777650      CoRR  Karan Singhal;Shekoofeh Azizi;Tao Tu;S. Sara M...   \n",
       "507262  777989      CoRR                          Ashley Liew;Klaus Mueller   \n",
       "507263  778319      CoRR  Yinlin Deng;Chunqiu Steven Xia;Haoran Peng;Che...   \n",
       "\n",
       "                                                    title  \\\n",
       "507259  Benchmarking Large Language Models for Automat...   \n",
       "507260  Why Does Surprisal From Larger Transformer-Bas...   \n",
       "507261   Large Language Models Encode Clinical Knowledge.   \n",
       "507262  Using Large Language Models to Generate Engagi...   \n",
       "507263  Fuzzing Deep-Learning Libraries via Large Lang...   \n",
       "\n",
       "                              doi categories  \\\n",
       "507259  10.48550/ARXIV.2212.11140        NaN   \n",
       "507260  10.48550/ARXIV.2212.12131        NaN   \n",
       "507261  10.48550/ARXIV.2212.13138        NaN   \n",
       "507262  10.48550/ARXIV.2212.14047        NaN   \n",
       "507263  10.48550/ARXIV.2212.14834        NaN   \n",
       "\n",
       "                                                 abstract versions  \\\n",
       "507259  Benchmarking Large Language Models for Automat...      NaN   \n",
       "507260  Why Does Surprisal From Larger Transformer-Bas...      NaN   \n",
       "507261   Large Language Models Encode Clinical Knowledge.      NaN   \n",
       "507262  Using Large Language Models to Generate Engagi...      NaN   \n",
       "507263  Fuzzing Deep-Learning Libraries via Large Lang...      NaN   \n",
       "\n",
       "       update_date                                     authors_parsed date  \\\n",
       "507259         NaN  [[Baleegh Ahmad], [Shailja Thakur], [Benjamin ...  NaT   \n",
       "507260         NaN                [[Byung-Doh Oh], [William Schuler]]  NaT   \n",
       "507261         NaN  [[Hyung Won Chung], [Tao Tu], [Nathan Scales],...  NaT   \n",
       "507262         NaN                   [[Klaus Mueller], [Ashley Liew]]  NaT   \n",
       "507263         NaN  [[Yinlin Deng], [Haoran Peng], [Chenyuan Yang]...  NaT   \n",
       "\n",
       "        year  \n",
       "507259  2022  \n",
       "507260  2022  \n",
       "507261  2022  \n",
       "507262  2022  \n",
       "507263  2022  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Function to parse authors from the 'authors' column\n",
    "def parse_authors(authors_str):\n",
    "    authors_list = []\n",
    "    if isinstance(authors_str, str):\n",
    "        authors_parts = authors_str.split(';')\n",
    "        for part in authors_parts:\n",
    "            authors_list.append([part.strip()])\n",
    "    return authors_list\n",
    "\n",
    "# Apply the parsing function to 'authors' column where 'authors_parsed' is NaN\n",
    "def parse_or_fill_authors(row):\n",
    "    if isinstance(row['authors_parsed'], float):  # Check for NaN using isinstance\n",
    "        return parse_authors(row['authors'])\n",
    "    else:\n",
    "        return row['authors_parsed']\n",
    "\n",
    "# Apply the parsing or filling function to 'authors_parsed' column with tqdm\n",
    "tqdm.pandas()  # Enable tqdm for pandas operations\n",
    "papers['authors_parsed'] = papers.progress_apply(parse_or_fill_authors, axis=1)\n",
    "\n",
    "# Function to remove duplicates from authors list\n",
    "def remove_duplicates(authors_list):\n",
    "    return [list(author) for author in set(tuple(author) for author in authors_list)]\n",
    "\n",
    "# Apply the remove_duplicates function to 'authors_parsed' column with tqdm\n",
    "papers['authors_parsed'] = papers['authors_parsed'].progress_apply(remove_duplicates)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "papers.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9715001-8db5-41fd-bd70-a8b189e663af",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "# Function to preprocess title and abstract\n",
    "def preprocess_text(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in STOPWORDS]\n",
    "    filtered_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "    filtered_words = preprocess_string(' '.join(filtered_words), custom_text_filters)\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "\n",
    "papers['processed_titles_abstracts'] = papers.apply(lambda row: preprocess_text(row['title'] + ' ' + row['abstract']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a60bbbd-cbe9-480c-9b52-dfc5c016faed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nested satisfiability special case satisfiability problem clause hierarchical structure shown solvable linear time assuming clause represented convenient way'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers['processed_titles_abstracts'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f0340ee-ca57-4819-9839-124f4d6f246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers.drop(['id', 'submitter', 'doi'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40131e2b-dcb3-444b-aa18-ac9230184648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "507264"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6aa7ca1-049c-404c-85dd-8e9bebe581ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>processed_titles_abstracts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald E. Knuth</td>\n",
       "      <td>Nested satisfiability</td>\n",
       "      <td>cs.CC</td>\n",
       "      <td>A special case of the satisfiability problem...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 1 Jan 1990...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Knuth, Donald E., ]]</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>1990</td>\n",
       "      <td>nested satisfiability special case satisfiabil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald E. Knuth</td>\n",
       "      <td>A note on digitized angles</td>\n",
       "      <td>cs.GR</td>\n",
       "      <td>We study the configurations of pixels that o...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Apr 1990...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Knuth, Donald E., ]]</td>\n",
       "      <td>1990-04-01</td>\n",
       "      <td>1990</td>\n",
       "      <td>note digitized angle study configuration pixel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald E. Knuth</td>\n",
       "      <td>Textbook examples of recursion</td>\n",
       "      <td>cs.CC</td>\n",
       "      <td>We discuss properties of recursive schemas r...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Thu, 1 Aug 1991...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Knuth, Donald E., ]]</td>\n",
       "      <td>1991-08-01</td>\n",
       "      <td>1991</td>\n",
       "      <td>textbook example recursion discus property rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald E. Knuth</td>\n",
       "      <td>Theory and practice</td>\n",
       "      <td>cs.GL</td>\n",
       "      <td>The author argues to Silicon Valley that the...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Fri, 1 Nov 1991...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Knuth, Donald E., ]]</td>\n",
       "      <td>1991-11-01</td>\n",
       "      <td>1991</td>\n",
       "      <td>theory practice author argues silicon valley i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald E. Knuth</td>\n",
       "      <td>Context-free multilanguages</td>\n",
       "      <td>cs.DS</td>\n",
       "      <td>This article is a sketch of ideas that were ...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Dec 1991...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Knuth, Donald E., ]]</td>\n",
       "      <td>1991-12-01</td>\n",
       "      <td>1991</td>\n",
       "      <td>context free multilanguages icle sketch idea i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Donald E. Knuth, Arvind Raghunathan</td>\n",
       "      <td>The problem of compatible representatives</td>\n",
       "      <td>cs.DS math.CO</td>\n",
       "      <td>The purpose of this note is to attach a name...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Wed, 1 Jul 1992...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Raghunathan, Arvind, ], [Knuth, Donald E., ]]</td>\n",
       "      <td>1992-07-01</td>\n",
       "      <td>1992</td>\n",
       "      <td>problem patible representative purpose note at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M. P. Wellman</td>\n",
       "      <td>A Market-Oriented Programming Environment and ...</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>Market price systems constitute a well-under...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Aug 1993...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Wellman, M. P., ]]</td>\n",
       "      <td>1993-08-01</td>\n",
       "      <td>1993</td>\n",
       "      <td>market oriented programming environment applic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M. L. Ginsberg</td>\n",
       "      <td>Dynamic Backtracking</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>Because of their occasional need to return t...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Aug 1993...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Ginsberg, M. L., ]]</td>\n",
       "      <td>1993-08-01</td>\n",
       "      <td>1993</td>\n",
       "      <td>dynamic backtracking occasional need return sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I. P. Gent, T. Walsh</td>\n",
       "      <td>An Empirical Analysis of Search in GSAT</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>We describe an extensive study of search in ...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Wed, 1 Sep 1993...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Gent, I. P., ], [Walsh, T., ]]</td>\n",
       "      <td>1993-09-01</td>\n",
       "      <td>1993</td>\n",
       "      <td>empirical analysis search gsat extensive study...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>J. C. Schlimmer, L. A. Hermens</td>\n",
       "      <td>Software Agents: Completing Patterns and Const...</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>To support the goal of allowing users to rec...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 1 Nov 1993...</td>\n",
       "      <td>2009-09-25</td>\n",
       "      <td>[[Schlimmer, J. C., ], [Hermens, L. A., ]]</td>\n",
       "      <td>1993-11-01</td>\n",
       "      <td>1993</td>\n",
       "      <td>software agents pleting patterns constructing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F. Bergadano, D. Gunetti, U. Trinchero</td>\n",
       "      <td>The Difficulties of Learning Logic Programs wi...</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>As real logic programmers normally use cut (...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 1 Nov 1993...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Trinchero, U., ], [Gunetti, D., ], [Bergadan...</td>\n",
       "      <td>1993-11-01</td>\n",
       "      <td>1993</td>\n",
       "      <td>difficulties learning logic programs cut logic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M. Buchheit, F. M. Donini, A. Schaerf</td>\n",
       "      <td>Decidable Reasoning in Terminological Knowledg...</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>Terminological knowledge representation syst...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Wed, 1 Dec 1993...</td>\n",
       "      <td>2014-11-17</td>\n",
       "      <td>[[Buchheit, M., ], [Schaerf, A., ], [Donini, F...</td>\n",
       "      <td>1993-12-01</td>\n",
       "      <td>1993</td>\n",
       "      <td>decidable reasoning terminological knowledge r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>N. Nilsson</td>\n",
       "      <td>Teleo-Reactive Programs for Agent Control</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>A formalism is presented for computing and o...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 1 Jan 1994...</td>\n",
       "      <td>2014-11-17</td>\n",
       "      <td>[[Nilsson, N., ]]</td>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>1994</td>\n",
       "      <td>teleo reactive programs agent control formalis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Donald E. Knuth</td>\n",
       "      <td>Mini-indexes for literate programs</td>\n",
       "      <td>cs.PL</td>\n",
       "      <td>This paper describes how to implement a docu...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 1 Jan 1994...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Knuth, Donald E., ]]</td>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>1994</td>\n",
       "      <td>mini indexes literate program describes implem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>M. Koppel, R. Feldman, A. M. Segre</td>\n",
       "      <td>Bias-Driven Revision of Logical Domain Theories</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>The theory revision problem is the problem o...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Tue, 1 Feb 1994...</td>\n",
       "      <td>2014-11-17</td>\n",
       "      <td>[[Koppel, M., ], [Feldman, R., ], [Segre, A. M...</td>\n",
       "      <td>1994-02-01</td>\n",
       "      <td>1994</td>\n",
       "      <td>bias driven revision logical domain theories t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>D. J. Cook, L. B. Holder</td>\n",
       "      <td>Substructure Discovery Using Minimum Descripti...</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>The ability to identify interesting and repe...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Tue, 1 Feb 1994...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Cook, D. J., ], [Holder, L. B., ]]</td>\n",
       "      <td>1994-02-01</td>\n",
       "      <td>1994</td>\n",
       "      <td>substructure discovery minimum description len...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C. X. Ling</td>\n",
       "      <td>Learning the Past Tense of English Verbs: The ...</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>Learning the past tense of English verbs - a...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Tue, 1 Feb 1994...</td>\n",
       "      <td>2009-09-25</td>\n",
       "      <td>[[Ling, C. X., ]]</td>\n",
       "      <td>1994-02-01</td>\n",
       "      <td>1994</td>\n",
       "      <td>learning past tense english verbs symbolic pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>P. M. Murphy, M. J. Pazzani</td>\n",
       "      <td>Exploring the Decision Forest: An Empirical In...</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>We report on a series of experiments in whic...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Tue, 1 Mar 1994...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Pazzani, M. J., ], [Murphy, P. M., ]]</td>\n",
       "      <td>1994-03-01</td>\n",
       "      <td>1994</td>\n",
       "      <td>exploring decision forest empirical investigat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>R. Sebastiani</td>\n",
       "      <td>Applying GSAT to Non-Clausal Formulas</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>In this paper we describe how to modify GSAT...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Wed, 1 Jun 1994...</td>\n",
       "      <td>2014-11-17</td>\n",
       "      <td>[[Sebastiani, R., ]]</td>\n",
       "      <td>1994-06-01</td>\n",
       "      <td>1994</td>\n",
       "      <td>applying gsat non clausal formulas modify gsat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A. Borgida, P. F. Patel-Schneider</td>\n",
       "      <td>A Semantics and Complete Algorithm for Subsump...</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>This paper analyzes the correctness of the s...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Wed, 1 Jun 1994...</td>\n",
       "      <td>2009-09-25</td>\n",
       "      <td>[[Borgida, A., ], [Patel-Schneider, P. F., ]]</td>\n",
       "      <td>1994-06-01</td>\n",
       "      <td>1994</td>\n",
       "      <td>semantics plete algorithm subsumption classic ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   authors  \\\n",
       "0                          Donald E. Knuth   \n",
       "1                          Donald E. Knuth   \n",
       "2                          Donald E. Knuth   \n",
       "3                          Donald E. Knuth   \n",
       "4                          Donald E. Knuth   \n",
       "5      Donald E. Knuth, Arvind Raghunathan   \n",
       "6                            M. P. Wellman   \n",
       "7                           M. L. Ginsberg   \n",
       "8                     I. P. Gent, T. Walsh   \n",
       "9           J. C. Schlimmer, L. A. Hermens   \n",
       "10  F. Bergadano, D. Gunetti, U. Trinchero   \n",
       "11   M. Buchheit, F. M. Donini, A. Schaerf   \n",
       "12                              N. Nilsson   \n",
       "13                         Donald E. Knuth   \n",
       "14      M. Koppel, R. Feldman, A. M. Segre   \n",
       "15                D. J. Cook, L. B. Holder   \n",
       "16                              C. X. Ling   \n",
       "17             P. M. Murphy, M. J. Pazzani   \n",
       "18                           R. Sebastiani   \n",
       "19       A. Borgida, P. F. Patel-Schneider   \n",
       "\n",
       "                                                title     categories  \\\n",
       "0                               Nested satisfiability          cs.CC   \n",
       "1                          A note on digitized angles          cs.GR   \n",
       "2                      Textbook examples of recursion          cs.CC   \n",
       "3                                 Theory and practice          cs.GL   \n",
       "4                         Context-free multilanguages          cs.DS   \n",
       "5           The problem of compatible representatives  cs.DS math.CO   \n",
       "6   A Market-Oriented Programming Environment and ...          cs.AI   \n",
       "7                                Dynamic Backtracking          cs.AI   \n",
       "8             An Empirical Analysis of Search in GSAT          cs.AI   \n",
       "9   Software Agents: Completing Patterns and Const...          cs.AI   \n",
       "10  The Difficulties of Learning Logic Programs wi...          cs.AI   \n",
       "11  Decidable Reasoning in Terminological Knowledg...          cs.AI   \n",
       "12          Teleo-Reactive Programs for Agent Control          cs.AI   \n",
       "13                 Mini-indexes for literate programs          cs.PL   \n",
       "14    Bias-Driven Revision of Logical Domain Theories          cs.AI   \n",
       "15  Substructure Discovery Using Minimum Descripti...          cs.AI   \n",
       "16  Learning the Past Tense of English Verbs: The ...          cs.AI   \n",
       "17  Exploring the Decision Forest: An Empirical In...          cs.AI   \n",
       "18              Applying GSAT to Non-Clausal Formulas          cs.AI   \n",
       "19  A Semantics and Complete Algorithm for Subsump...          cs.AI   \n",
       "\n",
       "                                             abstract  \\\n",
       "0     A special case of the satisfiability problem...   \n",
       "1     We study the configurations of pixels that o...   \n",
       "2     We discuss properties of recursive schemas r...   \n",
       "3     The author argues to Silicon Valley that the...   \n",
       "4     This article is a sketch of ideas that were ...   \n",
       "5     The purpose of this note is to attach a name...   \n",
       "6     Market price systems constitute a well-under...   \n",
       "7     Because of their occasional need to return t...   \n",
       "8     We describe an extensive study of search in ...   \n",
       "9     To support the goal of allowing users to rec...   \n",
       "10    As real logic programmers normally use cut (...   \n",
       "11    Terminological knowledge representation syst...   \n",
       "12    A formalism is presented for computing and o...   \n",
       "13    This paper describes how to implement a docu...   \n",
       "14    The theory revision problem is the problem o...   \n",
       "15    The ability to identify interesting and repe...   \n",
       "16    Learning the past tense of English verbs - a...   \n",
       "17    We report on a series of experiments in whic...   \n",
       "18    In this paper we describe how to modify GSAT...   \n",
       "19    This paper analyzes the correctness of the s...   \n",
       "\n",
       "                                             versions update_date  \\\n",
       "0   [{'version': 'v1', 'created': 'Mon, 1 Jan 1990...  2008-02-03   \n",
       "1   [{'version': 'v1', 'created': 'Sun, 1 Apr 1990...  2008-02-03   \n",
       "2   [{'version': 'v1', 'created': 'Thu, 1 Aug 1991...  2008-02-03   \n",
       "3   [{'version': 'v1', 'created': 'Fri, 1 Nov 1991...  2008-02-03   \n",
       "4   [{'version': 'v1', 'created': 'Sun, 1 Dec 1991...  2008-02-03   \n",
       "5   [{'version': 'v1', 'created': 'Wed, 1 Jul 1992...  2008-02-03   \n",
       "6   [{'version': 'v1', 'created': 'Sun, 1 Aug 1993...  2008-02-03   \n",
       "7   [{'version': 'v1', 'created': 'Sun, 1 Aug 1993...  2008-02-03   \n",
       "8   [{'version': 'v1', 'created': 'Wed, 1 Sep 1993...  2008-02-03   \n",
       "9   [{'version': 'v1', 'created': 'Mon, 1 Nov 1993...  2009-09-25   \n",
       "10  [{'version': 'v1', 'created': 'Mon, 1 Nov 1993...  2008-02-03   \n",
       "11  [{'version': 'v1', 'created': 'Wed, 1 Dec 1993...  2014-11-17   \n",
       "12  [{'version': 'v1', 'created': 'Sat, 1 Jan 1994...  2014-11-17   \n",
       "13  [{'version': 'v1', 'created': 'Sat, 1 Jan 1994...  2008-02-03   \n",
       "14  [{'version': 'v1', 'created': 'Tue, 1 Feb 1994...  2014-11-17   \n",
       "15  [{'version': 'v1', 'created': 'Tue, 1 Feb 1994...  2008-02-03   \n",
       "16  [{'version': 'v1', 'created': 'Tue, 1 Feb 1994...  2009-09-25   \n",
       "17  [{'version': 'v1', 'created': 'Tue, 1 Mar 1994...  2008-02-03   \n",
       "18  [{'version': 'v1', 'created': 'Wed, 1 Jun 1994...  2014-11-17   \n",
       "19  [{'version': 'v1', 'created': 'Wed, 1 Jun 1994...  2009-09-25   \n",
       "\n",
       "                                       authors_parsed       date  year  \\\n",
       "0                              [[Knuth, Donald E., ]] 1990-01-01  1990   \n",
       "1                              [[Knuth, Donald E., ]] 1990-04-01  1990   \n",
       "2                              [[Knuth, Donald E., ]] 1991-08-01  1991   \n",
       "3                              [[Knuth, Donald E., ]] 1991-11-01  1991   \n",
       "4                              [[Knuth, Donald E., ]] 1991-12-01  1991   \n",
       "5     [[Raghunathan, Arvind, ], [Knuth, Donald E., ]] 1992-07-01  1992   \n",
       "6                                [[Wellman, M. P., ]] 1993-08-01  1993   \n",
       "7                               [[Ginsberg, M. L., ]] 1993-08-01  1993   \n",
       "8                    [[Gent, I. P., ], [Walsh, T., ]] 1993-09-01  1993   \n",
       "9          [[Schlimmer, J. C., ], [Hermens, L. A., ]] 1993-11-01  1993   \n",
       "10  [[Trinchero, U., ], [Gunetti, D., ], [Bergadan... 1993-11-01  1993   \n",
       "11  [[Buchheit, M., ], [Schaerf, A., ], [Donini, F... 1993-12-01  1993   \n",
       "12                                  [[Nilsson, N., ]] 1994-01-01  1994   \n",
       "13                             [[Knuth, Donald E., ]] 1994-01-01  1994   \n",
       "14  [[Koppel, M., ], [Feldman, R., ], [Segre, A. M... 1994-02-01  1994   \n",
       "15               [[Cook, D. J., ], [Holder, L. B., ]] 1994-02-01  1994   \n",
       "16                                  [[Ling, C. X., ]] 1994-02-01  1994   \n",
       "17            [[Pazzani, M. J., ], [Murphy, P. M., ]] 1994-03-01  1994   \n",
       "18                               [[Sebastiani, R., ]] 1994-06-01  1994   \n",
       "19      [[Borgida, A., ], [Patel-Schneider, P. F., ]] 1994-06-01  1994   \n",
       "\n",
       "                           processed_titles_abstracts  \n",
       "0   nested satisfiability special case satisfiabil...  \n",
       "1   note digitized angle study configuration pixel...  \n",
       "2   textbook example recursion discus property rec...  \n",
       "3   theory practice author argues silicon valley i...  \n",
       "4   context free multilanguages icle sketch idea i...  \n",
       "5   problem patible representative purpose note at...  \n",
       "6   market oriented programming environment applic...  \n",
       "7   dynamic backtracking occasional need return sh...  \n",
       "8   empirical analysis search gsat extensive study...  \n",
       "9   software agents pleting patterns constructing ...  \n",
       "10  difficulties learning logic programs cut logic...  \n",
       "11  decidable reasoning terminological knowledge r...  \n",
       "12  teleo reactive programs agent control formalis...  \n",
       "13  mini indexes literate program describes implem...  \n",
       "14  bias driven revision logical domain theories t...  \n",
       "15  substructure discovery minimum description len...  \n",
       "16  learning past tense english verbs symbolic pat...  \n",
       "17  exploring decision forest empirical investigat...  \n",
       "18  applying gsat non clausal formulas modify gsat...  \n",
       "19  semantics plete algorithm subsumption classic ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24e54ab9-1807-491e-b384-989f1e8de08f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>processed_titles_abstracts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>507259</th>\n",
       "      <td>Shailja Thakur;Baleegh Ahmad;Zhenxing Fan;Hamm...</td>\n",
       "      <td>Benchmarking Large Language Models for Automat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benchmarking Large Language Models for Automat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Baleegh Ahmad], [Shailja Thakur], [Benjamin ...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "      <td>benchmarking large language models automated v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507260</th>\n",
       "      <td>Byung-Doh Oh;William Schuler</td>\n",
       "      <td>Why Does Surprisal From Larger Transformer-Bas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Why Does Surprisal From Larger Transformer-Bas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Byung-Doh Oh], [William Schuler]]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "      <td>surprisal larger transformer based language mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507261</th>\n",
       "      <td>Karan Singhal;Shekoofeh Azizi;Tao Tu;S. Sara M...</td>\n",
       "      <td>Large Language Models Encode Clinical Knowledge.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Large Language Models Encode Clinical Knowledge.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Hyung Won Chung], [Tao Tu], [Nathan Scales],...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "      <td>large language models encode clinical knowledg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507262</th>\n",
       "      <td>Ashley Liew;Klaus Mueller</td>\n",
       "      <td>Using Large Language Models to Generate Engagi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Using Large Language Models to Generate Engagi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Klaus Mueller], [Ashley Liew]]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "      <td>large language models generate engaging captio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507263</th>\n",
       "      <td>Yinlin Deng;Chunqiu Steven Xia;Haoran Peng;Che...</td>\n",
       "      <td>Fuzzing Deep-Learning Libraries via Large Lang...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fuzzing Deep-Learning Libraries via Large Lang...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Yinlin Deng], [Haoran Peng], [Chenyuan Yang]...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "      <td>fuzzing deep learning libraries large language...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  authors  \\\n",
       "507259  Shailja Thakur;Baleegh Ahmad;Zhenxing Fan;Hamm...   \n",
       "507260                       Byung-Doh Oh;William Schuler   \n",
       "507261  Karan Singhal;Shekoofeh Azizi;Tao Tu;S. Sara M...   \n",
       "507262                          Ashley Liew;Klaus Mueller   \n",
       "507263  Yinlin Deng;Chunqiu Steven Xia;Haoran Peng;Che...   \n",
       "\n",
       "                                                    title categories  \\\n",
       "507259  Benchmarking Large Language Models for Automat...        NaN   \n",
       "507260  Why Does Surprisal From Larger Transformer-Bas...        NaN   \n",
       "507261   Large Language Models Encode Clinical Knowledge.        NaN   \n",
       "507262  Using Large Language Models to Generate Engagi...        NaN   \n",
       "507263  Fuzzing Deep-Learning Libraries via Large Lang...        NaN   \n",
       "\n",
       "                                                 abstract versions  \\\n",
       "507259  Benchmarking Large Language Models for Automat...      NaN   \n",
       "507260  Why Does Surprisal From Larger Transformer-Bas...      NaN   \n",
       "507261   Large Language Models Encode Clinical Knowledge.      NaN   \n",
       "507262  Using Large Language Models to Generate Engagi...      NaN   \n",
       "507263  Fuzzing Deep-Learning Libraries via Large Lang...      NaN   \n",
       "\n",
       "       update_date                                     authors_parsed date  \\\n",
       "507259         NaN  [[Baleegh Ahmad], [Shailja Thakur], [Benjamin ...  NaT   \n",
       "507260         NaN                [[Byung-Doh Oh], [William Schuler]]  NaT   \n",
       "507261         NaN  [[Hyung Won Chung], [Tao Tu], [Nathan Scales],...  NaT   \n",
       "507262         NaN                   [[Klaus Mueller], [Ashley Liew]]  NaT   \n",
       "507263         NaN  [[Yinlin Deng], [Haoran Peng], [Chenyuan Yang]...  NaT   \n",
       "\n",
       "        year                         processed_titles_abstracts  \n",
       "507259  2022  benchmarking large language models automated v...  \n",
       "507260  2022  surprisal larger transformer based language mo...  \n",
       "507261  2022  large language models encode clinical knowledg...  \n",
       "507262  2022  large language models generate engaging captio...  \n",
       "507263  2022  fuzzing deep learning libraries large language...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d784e51-9f36-4cf0-b796-300187361acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>processed_titles_abstracts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501677</th>\n",
       "      <td>Yongsiriwit K.; Assy N.; Gaaloul W.</td>\n",
       "      <td>A semantic framework for configurable business...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>With the advent of Cloud Computing, new opport...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Gaaloul W.], [Assy N.], [Yongsiriwit K.]]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016</td>\n",
       "      <td>semantic framework configurable business proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501678</th>\n",
       "      <td>Qi J.; Ohsawa Y.</td>\n",
       "      <td>Matrix-like visualization based on topic model...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interdisciplinary research is challenging beca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Ohsawa Y.], [Qi J.]]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016</td>\n",
       "      <td>matrix like visualization based topic modeling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501679</th>\n",
       "      <td>Wang X.; Zhu P.; Liu T.; Xu K.</td>\n",
       "      <td>BioTopic: A topic-driven biological literature...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Biology and biomedicine are flourishing discip...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Xu K.], [Liu T.], [Zhu P.], [Wang X.]]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016</td>\n",
       "      <td>biotopic topic driven biological literature mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501681</th>\n",
       "      <td>George R.; Samuel P.</td>\n",
       "      <td>Particle swarm optimization method based consi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unified Modeling Language models are the de fa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Samuel P.], [George R.]]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016</td>\n",
       "      <td>picle swarm optimization method based consiste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501682</th>\n",
       "      <td>Guadarrama S.; Rodner E.; Saenko K.; Darrell T.</td>\n",
       "      <td>Understanding object descriptions in robotics ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We address the problem of retrieving and detec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Guadarrama S.], [Rodner E.], [Darrell T.], [...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016</td>\n",
       "      <td>understanding object description robotics open...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                authors  \\\n",
       "501677              Yongsiriwit K.; Assy N.; Gaaloul W.   \n",
       "501678                                 Qi J.; Ohsawa Y.   \n",
       "501679                   Wang X.; Zhu P.; Liu T.; Xu K.   \n",
       "501681                             George R.; Samuel P.   \n",
       "501682  Guadarrama S.; Rodner E.; Saenko K.; Darrell T.   \n",
       "\n",
       "                                                    title categories  \\\n",
       "501677  A semantic framework for configurable business...        NaN   \n",
       "501678  Matrix-like visualization based on topic model...        NaN   \n",
       "501679  BioTopic: A topic-driven biological literature...        NaN   \n",
       "501681  Particle swarm optimization method based consi...        NaN   \n",
       "501682  Understanding object descriptions in robotics ...        NaN   \n",
       "\n",
       "                                                 abstract versions  \\\n",
       "501677  With the advent of Cloud Computing, new opport...      NaN   \n",
       "501678  Interdisciplinary research is challenging beca...      NaN   \n",
       "501679  Biology and biomedicine are flourishing discip...      NaN   \n",
       "501681  Unified Modeling Language models are the de fa...      NaN   \n",
       "501682  We address the problem of retrieving and detec...      NaN   \n",
       "\n",
       "       update_date                                     authors_parsed date  \\\n",
       "501677         NaN        [[Gaaloul W.], [Assy N.], [Yongsiriwit K.]]  NaT   \n",
       "501678         NaN                             [[Ohsawa Y.], [Qi J.]]  NaT   \n",
       "501679         NaN           [[Xu K.], [Liu T.], [Zhu P.], [Wang X.]]  NaT   \n",
       "501681         NaN                         [[Samuel P.], [George R.]]  NaT   \n",
       "501682         NaN  [[Guadarrama S.], [Rodner E.], [Darrell T.], [...  NaT   \n",
       "\n",
       "        year                         processed_titles_abstracts  \n",
       "501677  2016  semantic framework configurable business proce...  \n",
       "501678  2016  matrix like visualization based topic modeling...  \n",
       "501679  2016  biotopic topic driven biological literature mi...  \n",
       "501681  2016  picle swarm optimization method based consiste...  \n",
       "501682  2016  understanding object description robotics open...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[papers['year'] == 2016].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "000c7f5b-de58-458c-9e67-089338491b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the 'papers' DataFrame to include data between '2010' and '2023'\n",
    "papers_2017_2023 = papers.loc[(papers['year'] >= 2017) & (papers['year'] <= 2023)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adf58ec-59e7-432c-aa26-a4daa52549f1",
   "metadata": {},
   "source": [
    "# Number of all research paper submissions per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52426a1f-28b2-4d20-bc85-fb92af0cf315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_38.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Group the 'papers' DataFrame by year and calculate the number of research paper submissions per year\n",
    "yearly_papers_submission_count = papers.groupby(papers['year']).size().reset_index().rename(columns={0:\"count\"})\n",
    "\n",
    "fig = px.line(x=\"year\",\n",
    "              y=\"count\",\n",
    "              data_frame=yearly_papers_submission_count,title=\"Number of research paper submissions per year\",\n",
    "              labels={\"date\": \"year\",\"count\": \"number of papers submitted\"})\n",
    "fig.update_traces(textposition=\"bottom right\")\n",
    "fig.update_layout(xaxis = dict(dtick = 1, tickangle=-45), title_x=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd34d56-2e94-44d5-8dfc-3db36d866185",
   "metadata": {},
   "source": [
    "# Number of submissions containing large language model per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d72ec37c-d271-475c-b13e-c704e8383892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_terms_in_abstract_title(abstract_title):\n",
    "    abstract_title_lower = abstract_title.lower()\n",
    "    \n",
    "    pattern_1 = r\"(large|big|massive)\\s+language\\s+(model|models)\"\n",
    "    pattern_2 = r\"\\b(ChatGPT|BERT|GPT|LLM|LLMS)\\b\"\n",
    "    \n",
    "    combined_pattern = f\"({pattern_1})|({pattern_2})\"\n",
    "    \n",
    "    return re.search(combined_pattern, abstract_title_lower, re.IGNORECASE) is not None\n",
    "    \n",
    "def check_non_llm_paper(abstract_title):\n",
    "    return not check_terms_in_abstract_title(abstract_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa701f7a-9141-4064-9c9a-cb9a5c31c928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_40.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_papers = papers_2017_2023[(papers_2017_2023['processed_titles_abstracts']).apply(check_terms_in_abstract_title)]\n",
    "non_llm_papers = papers_2017_2023[papers_2017_2023['processed_titles_abstracts'].apply(check_non_llm_paper)]\n",
    "# Initialize an empty dictionary to store counts of papers containing 'large language model' per year\n",
    "count_papers = {}\n",
    "\n",
    "# Use tqdm to display a progress bar while processing the DataFrame\n",
    "tqdm.pandas(desc=\"Processing papers containing 'large language model'\")\n",
    "\n",
    "yearly_llm_submission = llm_papers.groupby('year').size().reset_index(name='count of large language model')\n",
    "\n",
    "# Plot the number of submissions containing 'large language model' per year\n",
    "fig = px.line(x=\"year\",y=\"count of large language model\",data_frame=yearly_llm_submission,title=\"Number of large language model research papers submissions per year\", text=\"count of large language model\")\n",
    "fig.update_traces(textposition=\"bottom right\")\n",
    "fig.update_layout(xaxis = dict(dtick = 1), title_x=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11418a91-08cb-47d1-8d09-a49d288c8bfa",
   "metadata": {},
   "source": [
    "# Researcher Profiling Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "faa9b162-ef4b-402b-84df-fc63c4132a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_to_print = 2016\n",
    "\n",
    "# Filter llm_papers for the specified year and print the full abstracts\n",
    "for authors_parsed in llm_papers[llm_papers['year'] == year_to_print]['authors_parsed']:\n",
    "    print(authors_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75b9910c-2b5d-4bd4-912e-edd081364d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>processed_titles_abstracts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>507259</th>\n",
       "      <td>Shailja Thakur;Baleegh Ahmad;Zhenxing Fan;Hamm...</td>\n",
       "      <td>Benchmarking Large Language Models for Automat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benchmarking Large Language Models for Automat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Baleegh Ahmad], [Shailja Thakur], [Benjamin ...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "      <td>benchmarking large language models automated v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507260</th>\n",
       "      <td>Byung-Doh Oh;William Schuler</td>\n",
       "      <td>Why Does Surprisal From Larger Transformer-Bas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Why Does Surprisal From Larger Transformer-Bas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Byung-Doh Oh], [William Schuler]]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "      <td>surprisal larger transformer based language mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507261</th>\n",
       "      <td>Karan Singhal;Shekoofeh Azizi;Tao Tu;S. Sara M...</td>\n",
       "      <td>Large Language Models Encode Clinical Knowledge.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Large Language Models Encode Clinical Knowledge.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Hyung Won Chung], [Tao Tu], [Nathan Scales],...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "      <td>large language models encode clinical knowledg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507262</th>\n",
       "      <td>Ashley Liew;Klaus Mueller</td>\n",
       "      <td>Using Large Language Models to Generate Engagi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Using Large Language Models to Generate Engagi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Klaus Mueller], [Ashley Liew]]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "      <td>large language models generate engaging captio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507263</th>\n",
       "      <td>Yinlin Deng;Chunqiu Steven Xia;Haoran Peng;Che...</td>\n",
       "      <td>Fuzzing Deep-Learning Libraries via Large Lang...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fuzzing Deep-Learning Libraries via Large Lang...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Yinlin Deng], [Haoran Peng], [Chenyuan Yang]...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "      <td>fuzzing deep learning libraries large language...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  authors  \\\n",
       "507259  Shailja Thakur;Baleegh Ahmad;Zhenxing Fan;Hamm...   \n",
       "507260                       Byung-Doh Oh;William Schuler   \n",
       "507261  Karan Singhal;Shekoofeh Azizi;Tao Tu;S. Sara M...   \n",
       "507262                          Ashley Liew;Klaus Mueller   \n",
       "507263  Yinlin Deng;Chunqiu Steven Xia;Haoran Peng;Che...   \n",
       "\n",
       "                                                    title categories  \\\n",
       "507259  Benchmarking Large Language Models for Automat...        NaN   \n",
       "507260  Why Does Surprisal From Larger Transformer-Bas...        NaN   \n",
       "507261   Large Language Models Encode Clinical Knowledge.        NaN   \n",
       "507262  Using Large Language Models to Generate Engagi...        NaN   \n",
       "507263  Fuzzing Deep-Learning Libraries via Large Lang...        NaN   \n",
       "\n",
       "                                                 abstract versions  \\\n",
       "507259  Benchmarking Large Language Models for Automat...      NaN   \n",
       "507260  Why Does Surprisal From Larger Transformer-Bas...      NaN   \n",
       "507261   Large Language Models Encode Clinical Knowledge.      NaN   \n",
       "507262  Using Large Language Models to Generate Engagi...      NaN   \n",
       "507263  Fuzzing Deep-Learning Libraries via Large Lang...      NaN   \n",
       "\n",
       "       update_date                                     authors_parsed date  \\\n",
       "507259         NaN  [[Baleegh Ahmad], [Shailja Thakur], [Benjamin ...  NaT   \n",
       "507260         NaN                [[Byung-Doh Oh], [William Schuler]]  NaT   \n",
       "507261         NaN  [[Hyung Won Chung], [Tao Tu], [Nathan Scales],...  NaT   \n",
       "507262         NaN                   [[Klaus Mueller], [Ashley Liew]]  NaT   \n",
       "507263         NaN  [[Yinlin Deng], [Haoran Peng], [Chenyuan Yang]...  NaT   \n",
       "\n",
       "        year                         processed_titles_abstracts  \n",
       "507259  2022  benchmarking large language models automated v...  \n",
       "507260  2022  surprisal larger transformer based language mo...  \n",
       "507261  2022  large language models encode clinical knowledg...  \n",
       "507262  2022  large language models generate engaging captio...  \n",
       "507263  2022  fuzzing deep learning libraries large language...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e401f3dc-d431-4aec-bdcb-10ac8b66c8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>processed_titles_abstracts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501677</th>\n",
       "      <td>Yongsiriwit K.; Assy N.; Gaaloul W.</td>\n",
       "      <td>A semantic framework for configurable business...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>With the advent of Cloud Computing, new opport...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Gaaloul W.], [Assy N.], [Yongsiriwit K.]]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016</td>\n",
       "      <td>semantic framework configurable business proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501678</th>\n",
       "      <td>Qi J.; Ohsawa Y.</td>\n",
       "      <td>Matrix-like visualization based on topic model...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interdisciplinary research is challenging beca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Ohsawa Y.], [Qi J.]]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016</td>\n",
       "      <td>matrix like visualization based topic modeling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501679</th>\n",
       "      <td>Wang X.; Zhu P.; Liu T.; Xu K.</td>\n",
       "      <td>BioTopic: A topic-driven biological literature...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Biology and biomedicine are flourishing discip...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Xu K.], [Liu T.], [Zhu P.], [Wang X.]]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016</td>\n",
       "      <td>biotopic topic driven biological literature mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501681</th>\n",
       "      <td>George R.; Samuel P.</td>\n",
       "      <td>Particle swarm optimization method based consi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unified Modeling Language models are the de fa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Samuel P.], [George R.]]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016</td>\n",
       "      <td>picle swarm optimization method based consiste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501682</th>\n",
       "      <td>Guadarrama S.; Rodner E.; Saenko K.; Darrell T.</td>\n",
       "      <td>Understanding object descriptions in robotics ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We address the problem of retrieving and detec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Guadarrama S.], [Rodner E.], [Darrell T.], [...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016</td>\n",
       "      <td>understanding object description robotics open...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                authors  \\\n",
       "501677              Yongsiriwit K.; Assy N.; Gaaloul W.   \n",
       "501678                                 Qi J.; Ohsawa Y.   \n",
       "501679                   Wang X.; Zhu P.; Liu T.; Xu K.   \n",
       "501681                             George R.; Samuel P.   \n",
       "501682  Guadarrama S.; Rodner E.; Saenko K.; Darrell T.   \n",
       "\n",
       "                                                    title categories  \\\n",
       "501677  A semantic framework for configurable business...        NaN   \n",
       "501678  Matrix-like visualization based on topic model...        NaN   \n",
       "501679  BioTopic: A topic-driven biological literature...        NaN   \n",
       "501681  Particle swarm optimization method based consi...        NaN   \n",
       "501682  Understanding object descriptions in robotics ...        NaN   \n",
       "\n",
       "                                                 abstract versions  \\\n",
       "501677  With the advent of Cloud Computing, new opport...      NaN   \n",
       "501678  Interdisciplinary research is challenging beca...      NaN   \n",
       "501679  Biology and biomedicine are flourishing discip...      NaN   \n",
       "501681  Unified Modeling Language models are the de fa...      NaN   \n",
       "501682  We address the problem of retrieving and detec...      NaN   \n",
       "\n",
       "       update_date                                     authors_parsed date  \\\n",
       "501677         NaN        [[Gaaloul W.], [Assy N.], [Yongsiriwit K.]]  NaT   \n",
       "501678         NaN                             [[Ohsawa Y.], [Qi J.]]  NaT   \n",
       "501679         NaN           [[Xu K.], [Liu T.], [Zhu P.], [Wang X.]]  NaT   \n",
       "501681         NaN                         [[Samuel P.], [George R.]]  NaT   \n",
       "501682         NaN  [[Guadarrama S.], [Rodner E.], [Darrell T.], [...  NaT   \n",
       "\n",
       "        year                         processed_titles_abstracts  \n",
       "501677  2016  semantic framework configurable business proce...  \n",
       "501678  2016  matrix like visualization based topic modeling...  \n",
       "501679  2016  biotopic topic driven biological literature mi...  \n",
       "501681  2016  picle swarm optimization method based consiste...  \n",
       "501682  2016  understanding object description robotics open...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[papers['year'] == 2016].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08f3180f-9306-4078-9cdd-527ea20b3669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>processed_titles_abstracts</th>\n",
       "      <th>num_authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>507259</th>\n",
       "      <td>[Baleegh Ahmad, Shailja Thakur, Benjamin Tan, ...</td>\n",
       "      <td>Benchmarking Large Language Models for Automat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benchmarking Large Language Models for Automat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Baleegh Ahmad], [Shailja Thakur], [Benjamin ...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "      <td>benchmarking large language models automated v...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507260</th>\n",
       "      <td>[Byung-Doh Oh, William Schuler]</td>\n",
       "      <td>Why Does Surprisal From Larger Transformer-Bas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Why Does Surprisal From Larger Transformer-Bas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Byung-Doh Oh], [William Schuler]]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "      <td>surprisal larger transformer based language mo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507261</th>\n",
       "      <td>[Hyung Won Chung, Tao Tu, Nathan Scales, S. Sa...</td>\n",
       "      <td>Large Language Models Encode Clinical Knowledge.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Large Language Models Encode Clinical Knowledge.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Hyung Won Chung], [Tao Tu], [Nathan Scales],...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "      <td>large language models encode clinical knowledg...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507262</th>\n",
       "      <td>[Klaus Mueller, Ashley Liew]</td>\n",
       "      <td>Using Large Language Models to Generate Engagi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Using Large Language Models to Generate Engagi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Klaus Mueller], [Ashley Liew]]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "      <td>large language models generate engaging captio...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507263</th>\n",
       "      <td>[Yinlin Deng, Haoran Peng, Chenyuan Yang, Ling...</td>\n",
       "      <td>Fuzzing Deep-Learning Libraries via Large Lang...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fuzzing Deep-Learning Libraries via Large Lang...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Yinlin Deng], [Haoran Peng], [Chenyuan Yang]...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022</td>\n",
       "      <td>fuzzing deep learning libraries large language...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  authors  \\\n",
       "507259  [Baleegh Ahmad, Shailja Thakur, Benjamin Tan, ...   \n",
       "507260                    [Byung-Doh Oh, William Schuler]   \n",
       "507261  [Hyung Won Chung, Tao Tu, Nathan Scales, S. Sa...   \n",
       "507262                       [Klaus Mueller, Ashley Liew]   \n",
       "507263  [Yinlin Deng, Haoran Peng, Chenyuan Yang, Ling...   \n",
       "\n",
       "                                                    title categories  \\\n",
       "507259  Benchmarking Large Language Models for Automat...        NaN   \n",
       "507260  Why Does Surprisal From Larger Transformer-Bas...        NaN   \n",
       "507261   Large Language Models Encode Clinical Knowledge.        NaN   \n",
       "507262  Using Large Language Models to Generate Engagi...        NaN   \n",
       "507263  Fuzzing Deep-Learning Libraries via Large Lang...        NaN   \n",
       "\n",
       "                                                 abstract versions  \\\n",
       "507259  Benchmarking Large Language Models for Automat...      NaN   \n",
       "507260  Why Does Surprisal From Larger Transformer-Bas...      NaN   \n",
       "507261   Large Language Models Encode Clinical Knowledge.      NaN   \n",
       "507262  Using Large Language Models to Generate Engagi...      NaN   \n",
       "507263  Fuzzing Deep-Learning Libraries via Large Lang...      NaN   \n",
       "\n",
       "       update_date                                     authors_parsed date  \\\n",
       "507259         NaN  [[Baleegh Ahmad], [Shailja Thakur], [Benjamin ...  NaT   \n",
       "507260         NaN                [[Byung-Doh Oh], [William Schuler]]  NaT   \n",
       "507261         NaN  [[Hyung Won Chung], [Tao Tu], [Nathan Scales],...  NaT   \n",
       "507262         NaN                   [[Klaus Mueller], [Ashley Liew]]  NaT   \n",
       "507263         NaN  [[Yinlin Deng], [Haoran Peng], [Chenyuan Yang]...  NaT   \n",
       "\n",
       "        year                         processed_titles_abstracts  num_authors  \n",
       "507259  2022  benchmarking large language models automated v...            8  \n",
       "507260  2022  surprisal larger transformer based language mo...            2  \n",
       "507261  2022  large language models encode clinical knowledg...            8  \n",
       "507262  2022  large language models generate engaging captio...            2  \n",
       "507263  2022  fuzzing deep learning libraries large language...            5  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of authors\n",
    "papers['num_authors'] = papers['authors_parsed'].apply(lambda x: len(x) if isinstance(x, list) else np.nan)\n",
    "\n",
    "# Flatten and format authors' names\n",
    "papers['authors'] = papers['authors_parsed'].apply(lambda authors: [(\" \".join(author)).strip() for author in authors] if isinstance(authors, list) else [])\n",
    "\n",
    "papers.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8ab6ab5-0c46-42be-82a2-674e755054fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>processed_titles_abstracts</th>\n",
       "      <th>num_authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Knuth Donald E.]</td>\n",
       "      <td>Nested satisfiability</td>\n",
       "      <td>cs.CC</td>\n",
       "      <td>A special case of the satisfiability problem...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 1 Jan 1990...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Knuth, Donald E., ]]</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>1990</td>\n",
       "      <td>nested satisfiability special case satisfiabil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Knuth Donald E.]</td>\n",
       "      <td>A note on digitized angles</td>\n",
       "      <td>cs.GR</td>\n",
       "      <td>We study the configurations of pixels that o...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Apr 1990...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Knuth, Donald E., ]]</td>\n",
       "      <td>1990-04-01</td>\n",
       "      <td>1990</td>\n",
       "      <td>note digitized angle study configuration pixel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Knuth Donald E.]</td>\n",
       "      <td>Textbook examples of recursion</td>\n",
       "      <td>cs.CC</td>\n",
       "      <td>We discuss properties of recursive schemas r...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Thu, 1 Aug 1991...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Knuth, Donald E., ]]</td>\n",
       "      <td>1991-08-01</td>\n",
       "      <td>1991</td>\n",
       "      <td>textbook example recursion discus property rec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Knuth Donald E.]</td>\n",
       "      <td>Theory and practice</td>\n",
       "      <td>cs.GL</td>\n",
       "      <td>The author argues to Silicon Valley that the...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Fri, 1 Nov 1991...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Knuth, Donald E., ]]</td>\n",
       "      <td>1991-11-01</td>\n",
       "      <td>1991</td>\n",
       "      <td>theory practice author argues silicon valley i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Knuth Donald E.]</td>\n",
       "      <td>Context-free multilanguages</td>\n",
       "      <td>cs.DS</td>\n",
       "      <td>This article is a sketch of ideas that were ...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Dec 1991...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Knuth, Donald E., ]]</td>\n",
       "      <td>1991-12-01</td>\n",
       "      <td>1991</td>\n",
       "      <td>context free multilanguages icle sketch idea i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             authors                           title categories  \\\n",
       "0  [Knuth Donald E.]           Nested satisfiability      cs.CC   \n",
       "1  [Knuth Donald E.]      A note on digitized angles      cs.GR   \n",
       "2  [Knuth Donald E.]  Textbook examples of recursion      cs.CC   \n",
       "3  [Knuth Donald E.]             Theory and practice      cs.GL   \n",
       "4  [Knuth Donald E.]     Context-free multilanguages      cs.DS   \n",
       "\n",
       "                                            abstract  \\\n",
       "0    A special case of the satisfiability problem...   \n",
       "1    We study the configurations of pixels that o...   \n",
       "2    We discuss properties of recursive schemas r...   \n",
       "3    The author argues to Silicon Valley that the...   \n",
       "4    This article is a sketch of ideas that were ...   \n",
       "\n",
       "                                            versions update_date  \\\n",
       "0  [{'version': 'v1', 'created': 'Mon, 1 Jan 1990...  2008-02-03   \n",
       "1  [{'version': 'v1', 'created': 'Sun, 1 Apr 1990...  2008-02-03   \n",
       "2  [{'version': 'v1', 'created': 'Thu, 1 Aug 1991...  2008-02-03   \n",
       "3  [{'version': 'v1', 'created': 'Fri, 1 Nov 1991...  2008-02-03   \n",
       "4  [{'version': 'v1', 'created': 'Sun, 1 Dec 1991...  2008-02-03   \n",
       "\n",
       "           authors_parsed       date  year  \\\n",
       "0  [[Knuth, Donald E., ]] 1990-01-01  1990   \n",
       "1  [[Knuth, Donald E., ]] 1990-04-01  1990   \n",
       "2  [[Knuth, Donald E., ]] 1991-08-01  1991   \n",
       "3  [[Knuth, Donald E., ]] 1991-11-01  1991   \n",
       "4  [[Knuth, Donald E., ]] 1991-12-01  1991   \n",
       "\n",
       "                          processed_titles_abstracts  num_authors  \n",
       "0  nested satisfiability special case satisfiabil...            1  \n",
       "1  note digitized angle study configuration pixel...            1  \n",
       "2  textbook example recursion discus property rec...            1  \n",
       "3  theory practice author argues silicon valley i...            1  \n",
       "4  context free multilanguages icle sketch idea i...            1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df86f26c-d004-4ef9-8306-51363b5d4ee9",
   "metadata": {},
   "source": [
    "# Top Authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370beb6-a36e-45ed-bcae-68974b10e8b2",
   "metadata": {},
   "source": [
    "### Top 30 Popular Authors in preprint platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16dfbd2b-d754-4850-af7e-ca505813b12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                authors  Number of Papers Published\n",
      "274933         Liu Yang                         860\n",
      "366734  Poor H. Vincent                         671\n",
      "530329        Zhang Rui                         579\n",
      "456329      Tao Dacheng                         539\n",
      "490099         Wang Wei                         513\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"920\"\n",
       "    src=\"iframe_figures/figure_46.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Flatten the authors list\n",
    "authors_list = [author for authors in papers['authors'] for author in authors]\n",
    "# Create a DataFrame from the flattened list\n",
    "authors_df = pd.DataFrame({'authors': authors_list})\n",
    "# Group and count papers by authors\n",
    "papers_by_authors = authors_df.groupby(['authors']).size().reset_index(name='Number of Papers Published')\n",
    "papers_by_authors = papers_by_authors.sort_values(\"Number of Papers Published\", ascending=False).head(30)\n",
    "print(papers_by_authors.head())\n",
    "# Plot the bar chart using Plotly Express\n",
    "fig = px.bar(papers_by_authors.sort_values(\"Number of Papers Published\", ascending=True),\n",
    "             x=\"Number of Papers Published\", y=\"authors\",\n",
    "             title=\"Top 30 Popular Authors in preprint platform\", orientation=\"h\")\n",
    "fig.update_layout(\n",
    "    title_x=0.5,\n",
    "    yaxis=dict(automargin=True),\n",
    "    height=900\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b242902-c1d5-4c9a-9b1a-530adb2d8868",
   "metadata": {},
   "source": [
    "### Top 30 Popular Authors on large language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fdefe962-7d11-4f95-8507-00f37198b3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>processed_titles_abstracts</th>\n",
       "      <th>num_authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118707</th>\n",
       "      <td>[Vogel Stephan, Sajjad Hassan, Dalvi Fahim, Du...</td>\n",
       "      <td>QCRI Machine Translation Systems for IWSLT 16</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>This paper describes QCRI's machine translat...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 14 Jan 201...</td>\n",
       "      <td>2017-01-17</td>\n",
       "      <td>[[Vogel, Stephan, ], [Sajjad, Hassan, ], [Dalv...</td>\n",
       "      <td>2017-01-14 14:18:54</td>\n",
       "      <td>2017</td>\n",
       "      <td>qcri machine translation systems iwslt 16 desc...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119308</th>\n",
       "      <td>[Hinton Geoffrey, Le Quoc, Davis Andy, Mirhose...</td>\n",
       "      <td>Outrageously Large Neural Networks: The Sparse...</td>\n",
       "      <td>cs.LG cs.CL cs.NE stat.ML</td>\n",
       "      <td>The capacity of a neural network to absorb i...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 23 Jan 201...</td>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>[[Hinton, Geoffrey, ], [Le, Quoc, ], [Davis, A...</td>\n",
       "      <td>2017-01-23 18:10:00</td>\n",
       "      <td>2017</td>\n",
       "      <td>outrageously large neural networks sparsely ga...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141668</th>\n",
       "      <td>[Bennett Erin D., Nie Allen, Goodman Noah D.]</td>\n",
       "      <td>DisSent: Sentence Representation Learning from...</td>\n",
       "      <td>cs.CL cs.AI</td>\n",
       "      <td>Learning effective representations of senten...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Thu, 12 Oct 201...</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>[[Bennett, Erin D., ], [Nie, Allen, ], [Goodma...</td>\n",
       "      <td>2017-10-12 00:56:13</td>\n",
       "      <td>2017</td>\n",
       "      <td>dissent sentence representation learning expli...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164684</th>\n",
       "      <td>[Reitter David, Ororbia Alexander G., Mali Ank...</td>\n",
       "      <td>Like a Baby: Visually Situated Neural Language...</td>\n",
       "      <td>cs.CL cs.AI</td>\n",
       "      <td>We examine the benefits of visual context in...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Tue, 29 May 201...</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>[[Reitter, David, ], [Ororbia, Alexander G., ]...</td>\n",
       "      <td>2018-05-29 15:53:30</td>\n",
       "      <td>2018</td>\n",
       "      <td>like baby visually situated neural language ac...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167966</th>\n",
       "      <td>[Puchinger Sven, Renner Julian, Wachter-Zeh An...</td>\n",
       "      <td>Twisted Gabidulin Codes in the GPT Cryptosystem</td>\n",
       "      <td>cs.IT cs.CR math.IT</td>\n",
       "      <td>In this paper, we investigate twisted Gabidu...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Tue, 26 Jun 201...</td>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>[[Puchinger, Sven, ], [Renner, Julian, ], [Wac...</td>\n",
       "      <td>2018-06-26 15:14:43</td>\n",
       "      <td>2018</td>\n",
       "      <td>twisted gabidulin codes gpt cryptosystem inves...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  authors  \\\n",
       "118707  [Vogel Stephan, Sajjad Hassan, Dalvi Fahim, Du...   \n",
       "119308  [Hinton Geoffrey, Le Quoc, Davis Andy, Mirhose...   \n",
       "141668      [Bennett Erin D., Nie Allen, Goodman Noah D.]   \n",
       "164684  [Reitter David, Ororbia Alexander G., Mali Ank...   \n",
       "167966  [Puchinger Sven, Renner Julian, Wachter-Zeh An...   \n",
       "\n",
       "                                                    title  \\\n",
       "118707      QCRI Machine Translation Systems for IWSLT 16   \n",
       "119308  Outrageously Large Neural Networks: The Sparse...   \n",
       "141668  DisSent: Sentence Representation Learning from...   \n",
       "164684  Like a Baby: Visually Situated Neural Language...   \n",
       "167966    Twisted Gabidulin Codes in the GPT Cryptosystem   \n",
       "\n",
       "                       categories  \\\n",
       "118707                      cs.CL   \n",
       "119308  cs.LG cs.CL cs.NE stat.ML   \n",
       "141668                cs.CL cs.AI   \n",
       "164684                cs.CL cs.AI   \n",
       "167966        cs.IT cs.CR math.IT   \n",
       "\n",
       "                                                 abstract  \\\n",
       "118707    This paper describes QCRI's machine translat...   \n",
       "119308    The capacity of a neural network to absorb i...   \n",
       "141668    Learning effective representations of senten...   \n",
       "164684    We examine the benefits of visual context in...   \n",
       "167966    In this paper, we investigate twisted Gabidu...   \n",
       "\n",
       "                                                 versions update_date  \\\n",
       "118707  [{'version': 'v1', 'created': 'Sat, 14 Jan 201...  2017-01-17   \n",
       "119308  [{'version': 'v1', 'created': 'Mon, 23 Jan 201...  2017-01-24   \n",
       "141668  [{'version': 'v1', 'created': 'Thu, 12 Oct 201...  2019-06-05   \n",
       "164684  [{'version': 'v1', 'created': 'Tue, 29 May 201...  2019-06-05   \n",
       "167966  [{'version': 'v1', 'created': 'Tue, 26 Jun 201...  2018-08-15   \n",
       "\n",
       "                                           authors_parsed                date  \\\n",
       "118707  [[Vogel, Stephan, ], [Sajjad, Hassan, ], [Dalv... 2017-01-14 14:18:54   \n",
       "119308  [[Hinton, Geoffrey, ], [Le, Quoc, ], [Davis, A... 2017-01-23 18:10:00   \n",
       "141668  [[Bennett, Erin D., ], [Nie, Allen, ], [Goodma... 2017-10-12 00:56:13   \n",
       "164684  [[Reitter, David, ], [Ororbia, Alexander G., ]... 2018-05-29 15:53:30   \n",
       "167966  [[Puchinger, Sven, ], [Renner, Julian, ], [Wac... 2018-06-26 15:14:43   \n",
       "\n",
       "        year                         processed_titles_abstracts  num_authors  \n",
       "118707  2017  qcri machine translation systems iwslt 16 desc...            4  \n",
       "119308  2017  outrageously large neural networks sparsely ga...            7  \n",
       "141668  2017  dissent sentence representation learning expli...            3  \n",
       "164684  2018  like baby visually situated neural language ac...            4  \n",
       "167966  2018  twisted gabidulin codes gpt cryptosystem inves...            3  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_papers['num_authors'] = llm_papers['authors_parsed'].apply(lambda x:len(x))\n",
    "llm_papers['authors'] = llm_papers['authors_parsed'].apply(lambda authors:[(\" \".join(author)).strip() for author in authors])\n",
    "llm_papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ef57604-e692-495a-a198-1d4f59f53690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"920\"\n",
       "    src=\"iframe_figures/figure_48.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               author  Number of Papers Published\n",
      "0            Zhang Y.                          49\n",
      "1    Zettlemoyer Luke                          43\n",
      "2          Qiu Xipeng                          41\n",
      "3          Choi Yejin                          40\n",
      "4            Wei Furu                          40\n",
      "5        Gao Jianfeng                          38\n",
      "6               Li Y.                          35\n",
      "7         Liu Zhiyuan                          34\n",
      "8           Lin Jimmy                          33\n",
      "9            Liu Yang                          33\n",
      "10          Zhang Yue                          33\n",
      "11          Jiang Xin                          33\n",
      "12            Liu Qun                          33\n",
      "13     Huang Xuanjing                          31\n",
      "14      Xiong Caiming                          30\n",
      "15      Smith Noah A.                          30\n",
      "16          Ren Xiang                          30\n",
      "17          Huang Fei                          29\n",
      "18           Li Xiang                          29\n",
      "19    Schütze Hinrich                          29\n",
      "20        Sun Maosong                          29\n",
      "21  Wang William Yang                          29\n",
      "22           Liu Ting                          29\n",
      "23           Duan Nan                          28\n",
      "24      Joshi Raviraj                          28\n",
      "25        Liang Percy                          27\n",
      "26            Dong Li                          27\n",
      "27            Wang J.                          27\n",
      "28           Zhou Jie                          27\n",
      "29            Wang Y.                          26\n"
     ]
    }
   ],
   "source": [
    "# Flatten the authors list\n",
    "llm_authors_list = [author for authors in llm_papers['authors'] for author in authors]\n",
    "\n",
    "# Create a DataFrame from the flattened list\n",
    "authors_df = pd.DataFrame({'author': llm_authors_list})\n",
    "\n",
    "# Group and count papers by authors\n",
    "all_llm_top_authors = authors_df.groupby(['author']).size().reset_index(name='Number of Papers Published')\n",
    "llm_top_authors = all_llm_top_authors.sort_values(\"Number of Papers Published\", ascending=False).reset_index().iloc[0:30]\n",
    "llm_top_100_authors = all_llm_top_authors.sort_values(\"Number of Papers Published\", ascending=False).reset_index().iloc[0:100]\n",
    "llm_top_authors.drop('index', axis=1, inplace=True)\n",
    "# Plot the bar chart using Plotly Express\n",
    "fig = px.bar(llm_top_authors.sort_values(\"Number of Papers Published\", ascending=True),\n",
    "             x=\"Number of Papers Published\", y=\"author\",\n",
    "             title=\"Top 30 Popular Authors on large language model\", orientation=\"h\")\n",
    "fig.update_layout(\n",
    "    title_x=0.5,\n",
    "    yaxis=dict(automargin=True),\n",
    "    height=900\n",
    ")\n",
    "fig.show()\n",
    "print(llm_top_authors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f30f1cff-34ee-4b93-91ec-fcccdec0b7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"920\"\n",
       "    src=\"iframe_figures/figure_49.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Flatten the authors list\n",
    "authors_list = [author for authors in papers['authors'] for author in authors]\n",
    "\n",
    "# Create a DataFrame from the flattened list\n",
    "authors_df = pd.DataFrame({'authors': authors_list})\n",
    "\n",
    "# Group and count papers by authors\n",
    "papers_by_authors = authors_df.groupby(['authors']).size().reset_index(name='Number of Papers Published')\n",
    "papers_by_authors = papers_by_authors.sort_values(\"Number of Papers Published\", ascending=False).head(30)\n",
    "\n",
    "# Plot the bar chart using Plotly Express\n",
    "fig = px.bar(papers_by_authors.sort_values(\"Number of Papers Published\", ascending=True),\n",
    "             x=\"Number of Papers Published\", y=\"authors\",\n",
    "             title=\"Top 30 Popular Authors in preprint platform\", orientation=\"h\")\n",
    "fig.update_layout(\n",
    "    title_x=0.5,\n",
    "    yaxis=dict(automargin=True),\n",
    "    height=900\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27330b7d-686d-4515-afc1-eda443ad5ac2",
   "metadata": {},
   "source": [
    "### Top 5 authors and their publication count on large language model each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d83394c2-8e70-487d-84a3-f4e1ecd6707b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"1120\"\n",
       "    src=\"iframe_figures/figure_50.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44837\n"
     ]
    }
   ],
   "source": [
    "authors_years = []\n",
    "for index, row in llm_papers.iterrows():\n",
    "    authors = row['authors']\n",
    "    authors_years.extend([(author, row['year']) for author in authors])\n",
    "\n",
    "# Create a DataFrame from the flattened list\n",
    "authors_df = pd.DataFrame(authors_years, columns=['author', 'year'])\n",
    "\n",
    "# Group and count papers by authors and year\n",
    "llm_top_authors_by_year = authors_df.groupby(['author', 'year']).size().reset_index(name='Number of Papers Published')\n",
    "\n",
    "# Get the top 5 authors for each year\n",
    "top_authors_by_year = (\n",
    "    llm_top_authors_by_year.sort_values(['year', 'Number of Papers Published'], ascending=[True, False])\n",
    "    .groupby('year')\n",
    "    .head(5)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "top_authors_by_year = pd.DataFrame(top_authors_by_year)\n",
    "\n",
    "# Create a bar graph using Plotly Express\n",
    "fig = px.bar(top_authors_by_year, x='Number of Papers Published', y='author', color='year',\n",
    "             title='Top 5 authors and their publication count on large language model each year', orientation='h', text=\"Number of Papers Published\")\n",
    "fig.update_layout(yaxis={\"dtick\":1},coloraxis={\"colorbar\":{\"dtick\":1}},title_x=0.5,height=1100)\n",
    "fig.update_traces(textangle=0)\n",
    "fig.show()\n",
    "print(len(llm_top_authors_by_year))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caeb1ee-b0c7-4cee-b92d-ff8c144db1bf",
   "metadata": {},
   "source": [
    "# Key words used in the titles and abstract of the LLM papers published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44eb1c68-1101-4794-bb05-cdfbdac5649f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"920\"\n",
       "    src=\"iframe_figures/figure_51.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generating bigrams\n",
    "all_llm_bigrams = [\"_\".join(bigram) for title in llm_papers['processed_titles_abstracts'] for bigram in ngrams(nltk.word_tokenize(title), 2)]\n",
    "\n",
    "topn = 50\n",
    "\n",
    "# Counting bigram frequencies\n",
    "llm_bigram_counter = Counter(all_llm_bigrams)\n",
    "top_llm_bigrams = llm_bigram_counter.most_common(topn)\n",
    "\n",
    "# Creating a DataFrame for top bigrams\n",
    "top_llm_bigrams_df = pd.DataFrame(top_llm_bigrams, columns=['words', 'Frequency'])\n",
    "\n",
    "# Creating a horizontal bar chart using Plotly\n",
    "fig = px.bar(data_frame=top_llm_bigrams_df.sort_values(\"Frequency\", ascending=True),\n",
    "             x=\"Frequency\", y=\"words\", orientation=\"h\",\n",
    "             title=\"Top \" + str(topn) + \" Bigrams in LLM Papers\")\n",
    "\n",
    "fig.update_layout(yaxis={\"dtick\":1},title_x=0.5,height=900)\n",
    "fig.update_traces(textangle=0)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1d1ef2c-3468-4776-acc8-4da00a822174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"920\"\n",
       "    src=\"iframe_figures/figure_52.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>large_language_models</td>\n",
       "      <td>4706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>large_language_model</td>\n",
       "      <td>3450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natural_language_processing</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pre_trained_language</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>language_model_llms</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         words  Frequency\n",
       "0        large_language_models       4706\n",
       "1         large_language_model       3450\n",
       "2  natural_language_processing       1796\n",
       "3         pre_trained_language       1343\n",
       "4          language_model_llms       1208"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_llm_trigrams = [\"_\".join(trigram) for title in llm_papers['processed_titles_abstracts'] for trigram in ngrams(title.replace(\":\", \"\").split(), 3)]\n",
    "\n",
    "topn = 50\n",
    "\n",
    "# Counting trigram frequencies\n",
    "llm_trigram_counter = Counter(all_llm_trigrams)\n",
    "top_llm_trigrams = llm_trigram_counter.most_common(topn)\n",
    "\n",
    "# Creating a DataFrame for top trigrams\n",
    "top_llm_trigrams_df = pd.DataFrame(top_llm_trigrams, columns=['words', 'Frequency'])\n",
    "\n",
    "# Creating a horizontal bar chart using Plotly\n",
    "fig = px.bar(data_frame=top_llm_trigrams_df.sort_values(\"Frequency\", ascending=True),\n",
    "             x=\"Frequency\", \n",
    "             y=\"words\", \n",
    "             orientation=\"h\",\n",
    "             title=\"Top \" + str(topn) + \" Trigrams in Papers\")\n",
    "\n",
    "fig.update_layout(yaxis={\"dtick\":1},title_x=0.5,height=900)\n",
    "fig.update_traces(textangle=0)\n",
    "fig.show()\n",
    "top_llm_trigrams_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39cb1ae-f7dc-4686-a47e-534acdb30fc6",
   "metadata": {},
   "source": [
    "# Researcher Profiling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6f0e1dc3-c9d0-4bfa-bcde-1b30cb4b7706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network</td>\n",
       "      <td>79231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>machine_learning</td>\n",
       "      <td>54065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deep_learning</td>\n",
       "      <td>47917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>large_scale</td>\n",
       "      <td>36236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proposed_method</td>\n",
       "      <td>30588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reinforcement_learning</td>\n",
       "      <td>29701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>experimental_result</td>\n",
       "      <td>29385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neural_networks</td>\n",
       "      <td>28998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>propose_novel</td>\n",
       "      <td>25901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>natural_language</td>\n",
       "      <td>24382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    words  Frequency\n",
       "0          neural_network      79231\n",
       "1        machine_learning      54065\n",
       "2           deep_learning      47917\n",
       "3             large_scale      36236\n",
       "4         proposed_method      30588\n",
       "5  reinforcement_learning      29701\n",
       "6     experimental_result      29385\n",
       "7         neural_networks      28998\n",
       "8           propose_novel      25901\n",
       "9        natural_language      24382"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating bigrams\n",
    "all_bigrams = [\"_\".join(bigram) for title in papers['processed_titles_abstracts'] for bigram in ngrams(title.split(), 2)]\n",
    "\n",
    "topn = 50\n",
    "\n",
    "bigram_counter = Counter(all_bigrams)\n",
    "top_all_bigrams = bigram_counter.most_common(topn)\n",
    "\n",
    "# Creating a DataFrame for top bigrams\n",
    "top_bigrams_df = pd.DataFrame(top_all_bigrams, columns=['words', 'Frequency'])\n",
    "\n",
    "top_bigrams_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e45260f-0d43-43fb-8787-4aab62f083ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deep_neural_network</td>\n",
       "      <td>14940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>convolutional_neural_network</td>\n",
       "      <td>13550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natural_language_processing</td>\n",
       "      <td>10836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deep_reinforcement_learning</td>\n",
       "      <td>6204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deep_neural_networks</td>\n",
       "      <td>6085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deep_learning_model</td>\n",
       "      <td>5737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deep_learning_based</td>\n",
       "      <td>5718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>machine_learning_model</td>\n",
       "      <td>5653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>convolutional_neural_networks</td>\n",
       "      <td>5334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>recurrent_neural_network</td>\n",
       "      <td>4770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           words  Frequency\n",
       "0            deep_neural_network      14940\n",
       "1   convolutional_neural_network      13550\n",
       "2    natural_language_processing      10836\n",
       "3    deep_reinforcement_learning       6204\n",
       "4           deep_neural_networks       6085\n",
       "5            deep_learning_model       5737\n",
       "6            deep_learning_based       5718\n",
       "7         machine_learning_model       5653\n",
       "8  convolutional_neural_networks       5334\n",
       "9       recurrent_neural_network       4770"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating trigrams\n",
    "all_trigrams = [\"_\".join(trigram) for title in papers['processed_titles_abstracts'] for trigram in ngrams(nltk.word_tokenize(title), 3)]\n",
    "\n",
    "topn = 50\n",
    "\n",
    "# Counting trigram frequencies\n",
    "trigram_counter = Counter(all_trigrams)\n",
    "top_all_trigrams = trigram_counter.most_common(topn)\n",
    "\n",
    "# Creating DataFrames for top bigrams and trigrams\n",
    "top_trigrams_df = pd.DataFrame(top_all_trigrams, columns=['words', 'Frequency'])\n",
    "\n",
    "# Display the top 100 trigrams\n",
    "top_trigrams_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa1e61a2-b120-4d23-8315-05bbc432f3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>processed_titles_abstracts</th>\n",
       "      <th>num_authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Knuth Donald E.]</td>\n",
       "      <td>Nested satisfiability</td>\n",
       "      <td>cs.CC</td>\n",
       "      <td>A special case of the satisfiability problem...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 1 Jan 1990...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Knuth, Donald E., ]]</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>1990</td>\n",
       "      <td>nested satisfiability special case satisfiabil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Knuth Donald E.]</td>\n",
       "      <td>A note on digitized angles</td>\n",
       "      <td>cs.GR</td>\n",
       "      <td>We study the configurations of pixels that o...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Apr 1990...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Knuth, Donald E., ]]</td>\n",
       "      <td>1990-04-01</td>\n",
       "      <td>1990</td>\n",
       "      <td>note digitized angle study configuration pixel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Knuth Donald E.]</td>\n",
       "      <td>Textbook examples of recursion</td>\n",
       "      <td>cs.CC</td>\n",
       "      <td>We discuss properties of recursive schemas r...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Thu, 1 Aug 1991...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Knuth, Donald E., ]]</td>\n",
       "      <td>1991-08-01</td>\n",
       "      <td>1991</td>\n",
       "      <td>textbook example recursion discus property rec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Knuth Donald E.]</td>\n",
       "      <td>Theory and practice</td>\n",
       "      <td>cs.GL</td>\n",
       "      <td>The author argues to Silicon Valley that the...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Fri, 1 Nov 1991...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Knuth, Donald E., ]]</td>\n",
       "      <td>1991-11-01</td>\n",
       "      <td>1991</td>\n",
       "      <td>theory practice author argues silicon valley i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Knuth Donald E.]</td>\n",
       "      <td>Context-free multilanguages</td>\n",
       "      <td>cs.DS</td>\n",
       "      <td>This article is a sketch of ideas that were ...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Dec 1991...</td>\n",
       "      <td>2008-02-03</td>\n",
       "      <td>[[Knuth, Donald E., ]]</td>\n",
       "      <td>1991-12-01</td>\n",
       "      <td>1991</td>\n",
       "      <td>context free multilanguages icle sketch idea i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             authors                           title categories  \\\n",
       "0  [Knuth Donald E.]           Nested satisfiability      cs.CC   \n",
       "1  [Knuth Donald E.]      A note on digitized angles      cs.GR   \n",
       "2  [Knuth Donald E.]  Textbook examples of recursion      cs.CC   \n",
       "3  [Knuth Donald E.]             Theory and practice      cs.GL   \n",
       "4  [Knuth Donald E.]     Context-free multilanguages      cs.DS   \n",
       "\n",
       "                                            abstract  \\\n",
       "0    A special case of the satisfiability problem...   \n",
       "1    We study the configurations of pixels that o...   \n",
       "2    We discuss properties of recursive schemas r...   \n",
       "3    The author argues to Silicon Valley that the...   \n",
       "4    This article is a sketch of ideas that were ...   \n",
       "\n",
       "                                            versions update_date  \\\n",
       "0  [{'version': 'v1', 'created': 'Mon, 1 Jan 1990...  2008-02-03   \n",
       "1  [{'version': 'v1', 'created': 'Sun, 1 Apr 1990...  2008-02-03   \n",
       "2  [{'version': 'v1', 'created': 'Thu, 1 Aug 1991...  2008-02-03   \n",
       "3  [{'version': 'v1', 'created': 'Fri, 1 Nov 1991...  2008-02-03   \n",
       "4  [{'version': 'v1', 'created': 'Sun, 1 Dec 1991...  2008-02-03   \n",
       "\n",
       "           authors_parsed       date  year  \\\n",
       "0  [[Knuth, Donald E., ]] 1990-01-01  1990   \n",
       "1  [[Knuth, Donald E., ]] 1990-04-01  1990   \n",
       "2  [[Knuth, Donald E., ]] 1991-08-01  1991   \n",
       "3  [[Knuth, Donald E., ]] 1991-11-01  1991   \n",
       "4  [[Knuth, Donald E., ]] 1991-12-01  1991   \n",
       "\n",
       "                          processed_titles_abstracts  num_authors  \n",
       "0  nested satisfiability special case satisfiabil...            1  \n",
       "1  note digitized angle study configuration pixel...            1  \n",
       "2  textbook example recursion discus property rec...            1  \n",
       "3  theory practice author argues silicon valley i...            1  \n",
       "4  context free multilanguages icle sketch idea i...            1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66c23bcb-f6f6-42fa-a951-47a33823f611",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "papers_titles = papers['title'].tolist()\n",
    "titles = [title.lower() for title in papers_titles]  # Lowercasing the titles\n",
    "\n",
    "# Function to remove stopwords\n",
    "def remove_stop_words(title, stop_words):\n",
    "    words = title.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "papers_titles = [remove_stop_words(title, stop_words) for title in papers_titles]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412c30a8-ec42-49d3-887a-fa00acb3ed92",
   "metadata": {},
   "source": [
    "# Collaboration Trends in Research Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "63e42ad2-57ed-4907-a7bb-4771fc679e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_57.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the average number of authors per year\n",
    "mean_authors_per_year = llm_papers.groupby('year')['num_authors'].mean().round().reset_index()\n",
    "\n",
    "fig = px.bar(mean_authors_per_year,\n",
    "             x='year',\n",
    "             y='num_authors',\n",
    "             labels={'year': 'Year', 'num_authors': 'Average Number of Authors'},\n",
    "             text='num_authors')  # Set a color for the bars\n",
    "\n",
    "# Update layout to add main title and subtitle\n",
    "fig.update_layout(title_text='Average Number of Authors per Year ',  # Main title\n",
    "                  title_x=0.5,  # Center the main title\n",
    "                  xaxis=dict(tickmode='linear', tick0=0, dtick=1),  \n",
    "                  title_font_size=12,  # Font size for the main title\n",
    "                  title_pad_t=20,  # Padding at the top of the main title\n",
    "                  title_pad_b=10,  # Padding at the bottom of the main title\n",
    "                  title_y=0.95,  # Y-coordinate of the main title\n",
    "                  title_xanchor='center',  # Anchor point for the main title\n",
    "                  title_yanchor='top',  # Anchor point for the main title\n",
    "                  font=dict(size=16),  # Font size for the subtitle\n",
    "                  annotations=[dict(xref='paper', yref='paper', x=0.5, y=1.15,  # Subtitle position\n",
    "                                    text='Collaboration Trends on LLM',  # Subtitle text\n",
    "                                    showarrow=False)])  # Don't show arrow for subtitle annotation\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "df970f96-402a-48e6-ae20-22d6abfbfd14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_58.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the percentage of papers with more than 3 authors per year\n",
    "papers_with_multi_authors = (llm_papers[llm_papers['num_authors'] > 2]\n",
    "                             .groupby('year')['num_authors'].count() / llm_papers.groupby('year')['num_authors'].count() * 100).round().reset_index()\n",
    "\n",
    "# Create a bar plot for collaboration trends\n",
    "fig = px.bar(papers_with_multi_authors,\n",
    "             x='year',\n",
    "             y='num_authors',\n",
    "             labels={'year': 'Year', 'num_authors': 'Percentage of Papers'},\n",
    "             text='num_authors')\n",
    "\n",
    "# Update layout to add main title and subtitle\n",
    "fig.update_layout(title_text='Percentage of Papers with More than 2 Authors per Year',  # Main title\n",
    "                  title_x=0.5,  # Center the main title\n",
    "                  xaxis=dict(tickmode='linear', tick0=0, dtick=1),  \n",
    "                  title_font_size=12,  # Font size for the main title\n",
    "                  title_pad_t=20,  # Padding at the top of the main title\n",
    "                  title_pad_b=10,  # Padding at the bottom of the main title\n",
    "                  title_y=0.95,  # Y-coordinate of the main title\n",
    "                  title_xanchor='center',  # Anchor point for the main title\n",
    "                  title_yanchor='top',  # Anchor point for the main title\n",
    "                  font=dict(size=14),  # Font size for the subtitle\n",
    "                  annotations=[dict(xref='paper', yref='paper', x=0.5, y=1.15,  # Subtitle position\n",
    "                                    text='Collaboration Trends on LLM',  # Subtitle text\n",
    "                                    showarrow=False)])  # Don't show arrow for subtitle annotation\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6340a9e8-57b2-42a8-ad48-693612c52d40",
   "metadata": {},
   "source": [
    "# Researcher's Bigram and Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b8a3376-b9c0-4b3b-be48-bf0a0c3ac4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 371718/371718 [05:18<00:00, 1166.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram DataFrame:\n",
      "          frequency  year              word\n",
      "8333113       13022  2021    neural network\n",
      "11265640      12552  2022    neural network\n",
      "5681238       12372  2020    neural network\n",
      "3467841       10927  2019    neural network\n",
      "11265028      10313  2022  machine learning\n",
      "...             ...   ...               ...\n",
      "177110           21  2017   prediction deep\n",
      "177046           21  2017          rate wer\n",
      "3670836          21  2019        given test\n",
      "3498325          21  2019      driving task\n",
      "8737834          21  2021    efficient code\n",
      "\n",
      "[171241 rows x 3 columns]\n",
      "\n",
      " Trigram DataFrame:\n",
      "          frequency  year                            word\n",
      "16148173       2527  2021             deep neural network\n",
      "10746521       2507  2020             deep neural network\n",
      "6409682        2239  2019             deep neural network\n",
      "2784630        2234  2018    convolutional neural network\n",
      "22237000       2200  2022             deep neural network\n",
      "...             ...   ...                             ...\n",
      "23145099         21  2022          method achieve parable\n",
      "23147243         21  2022            neural network multi\n",
      "23149895         21  2022                           n 2 n\n",
      "16878118         21  2021  theoretical analysis empirical\n",
      "2950604          21  2018          pose estimation method\n",
      "\n",
      "[23563 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "top_20_authors = llm_top_authors['author']\n",
    "non_llm_publications = non_llm_papers[non_llm_papers['authors'].apply(lambda authors: any(author for author in top_20_authors))]\n",
    "\n",
    "# SUCCESS Initialize lists to store bigrams and trigrams with their years\n",
    "bigram_data = []\n",
    "trigram_data = []\n",
    "\n",
    "# Function to extract ngrams from text\n",
    "def extract_ngrams(text, n, year):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    n_grams = ngrams(tokens, n)\n",
    "    return [(year, ' '.join(gram)) for gram in n_grams]\n",
    "\n",
    "# Iterate over the DataFrame with tqdm for progress monitoring\n",
    "for _, row in tqdm(non_llm_publications.iterrows(), total=len(non_llm_publications)):\n",
    "    title_abstract = row['processed_titles_abstracts']\n",
    "    year = row['year']\n",
    "    \n",
    "    # Extract bigrams and trigrams\n",
    "    bigram_data.extend(extract_ngrams(title_abstract, 2, year))\n",
    "    trigram_data.extend(extract_ngrams(title_abstract, 3, year))\n",
    "\n",
    "# Calculate the frequency of bigrams and trigrams with years\n",
    "bigram_freq = Counter(bigram_data)\n",
    "trigram_freq = Counter(trigram_data)\n",
    "\n",
    "# Create DataFrames for bigrams and trigrams with years\n",
    "bigram_df = pd.DataFrame(list(bigram_freq.items()), columns=['(year, word)', 'frequency'])\n",
    "bigram_df[['year', 'word']] = pd.DataFrame(bigram_df['(year, word)'].tolist(), index=bigram_df.index)\n",
    "bigram_df.drop(columns=['(year, word)'], inplace=True)\n",
    "\n",
    "trigram_df = pd.DataFrame(list(trigram_freq.items()), columns=['(year, word)', 'frequency'])\n",
    "trigram_df[['year', 'word']] = pd.DataFrame(trigram_df['(year, word)'].tolist(), index=trigram_df.index)\n",
    "trigram_df.drop(columns=['(year, word)'], inplace=True)\n",
    "\n",
    "\n",
    "# Sort the bigram DataFrame by frequency in descending order\n",
    "bigram_df = bigram_df[bigram_df['frequency'] > 20].sort_values(by='frequency', ascending=False)\n",
    "\n",
    "# Sort the trigram DataFrame by frequency in descending order\n",
    "trigram_df = trigram_df[trigram_df['frequency'] > 20].sort_values(by='frequency', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(\"Bigram DataFrame:\")\n",
    "print(bigram_df)\n",
    "\n",
    "print(\"\\n Trigram DataFrame:\")\n",
    "print(trigram_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7ce37a0e-cd58-4944-8894-a3cd8c0e6886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>year</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [frequency, year, word]\n",
       "Index: []"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_df[bigram_df['year'] == 2016].nlargest(5, 'frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "821c8d6d-a731-4892-9e20-7421e9393823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 810/810 [00:28<00:00, 28.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm Bigram DataFrame:\n",
      "       frequency  year               word\n",
      "35468        335  2023     large language\n",
      "35343        289  2023     language model\n",
      "35469        196  2023    language models\n",
      "23398        144  2022     language model\n",
      "35355        110  2023   natural language\n",
      "...          ...   ...                ...\n",
      "26399          1  2022        tagging ner\n",
      "26400          1  2022            ner lid\n",
      "26401          1  2022        lid gluecos\n",
      "26402          1  2022  gluecos benchmark\n",
      "74004          1  2019     right reserved\n",
      "\n",
      "[74005 rows x 3 columns]\n",
      "\n",
      " llm Trigram DataFrame:\n",
      "       frequency  year                           word\n",
      "41491        189  2023           large language model\n",
      "41443        142  2023          large language models\n",
      "41616        100  2023            language model llms\n",
      "27505         45  2022           pre trained language\n",
      "27409         43  2022           large language model\n",
      "...          ...   ...                            ...\n",
      "30299          1  2022                    d way model\n",
      "30298          1  2022                     gpt2 d way\n",
      "30297          1  2022               attention gpt2 d\n",
      "30296          1  2022  unidirectional attention gpt2\n",
      "88804          1  2019        business right reserved\n",
      "\n",
      "[88805 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "top_20_authors = llm_top_authors['author']\n",
    "llm_publications = llm_papers[llm_papers['authors'].apply(lambda authors: any(author in authors for author in top_20_authors))]\n",
    "\n",
    "# SUCCESS Initialize lists to store bigrams and trigrams with their years\n",
    "llm_bigram_data = []\n",
    "llm_trigram_data = []\n",
    "\n",
    "# Function to extract ngrams from text\n",
    "def extract_ngrams(text, n, year):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    n_grams = ngrams(tokens, n)\n",
    "    return [(year, ' '.join(gram)) for gram in n_grams]\n",
    "\n",
    "# Iterate over the DataFrame with tqdm for progress monitoring\n",
    "for _, row in tqdm(llm_publications.iterrows(), total=len(llm_publications)):\n",
    "    title_abstract = row['processed_titles_abstracts']\n",
    "    year = row['year']\n",
    "    \n",
    "    # Extract bigrams and trigrams\n",
    "    llm_bigram_data.extend(extract_ngrams(title_abstract, 2, year))\n",
    "    llm_trigram_data.extend(extract_ngrams(title_abstract, 3, year))\n",
    "\n",
    "# Calculate the frequency of bigrams and trigrams with years\n",
    "llm_bigram_freq = Counter(llm_bigram_data)\n",
    "llm_trigram_freq = Counter(llm_trigram_data)\n",
    "\n",
    "# Create DataFrames for bigrams and trigrams with years\n",
    "llm_bigram_df = pd.DataFrame(list(llm_bigram_freq.items()), columns=['(year, word)', 'frequency'])\n",
    "llm_bigram_df[['year', 'word']] = pd.DataFrame(llm_bigram_df['(year, word)'].tolist(), index=llm_bigram_df.index)\n",
    "llm_bigram_df.drop(columns=['(year, word)'], inplace=True)\n",
    "\n",
    "llm_trigram_df = pd.DataFrame(list(llm_trigram_freq.items()), columns=['(year, word)', 'frequency'])\n",
    "llm_trigram_df[['year', 'word']] = pd.DataFrame(llm_trigram_df['(year, word)'].tolist(), index=llm_trigram_df.index)\n",
    "llm_trigram_df.drop(columns=['(year, word)'], inplace=True)\n",
    "\n",
    "\n",
    "# Sort the bigram DataFrame by frequency in descending order\n",
    "llm_bigram_df = llm_bigram_df.sort_values(by='frequency', ascending=False)\n",
    "\n",
    "# Sort the trigram DataFrame by frequency in descending order\n",
    "llm_trigram_df = llm_trigram_df.sort_values(by='frequency', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(\"llm Bigram DataFrame:\")\n",
    "print(llm_bigram_df)\n",
    "\n",
    "print(\"\\n llm Trigram DataFrame:\")\n",
    "print(llm_trigram_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0400c278-4b47-4dfb-a1bb-1204d00d3d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_62.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Calculate the frequency of large language model-related bigrams and trigrams for each year\n",
    "years = range(2010, 2024)  # Assuming you want to analyze from 2010 to 2023\n",
    "focus_data_top_authors = []\n",
    "focus_data_all_authors = []\n",
    "\n",
    "for year in years:\n",
    "    # Calculate the frequency for top 20 authors\n",
    "    year_non_llm_bigram_frequency = bigram_df[(bigram_df['year'] == year)]['frequency'].sum()\n",
    "    year_non_llm_trigram_frequency = trigram_df[(trigram_df['year'] == year)]['frequency'].sum()\n",
    "\n",
    "    # Calculate the frequency for all authors\n",
    "    year_llm_bigram_frequency_all = llm_bigram_df[(llm_bigram_df['year'] == year)]['frequency'].sum()\n",
    "    year_llm_trigram_frequency_all = llm_trigram_df[(llm_trigram_df['year'] == year)]['frequency'].sum()\n",
    "    \n",
    "    focus_data_top_authors.append({'Year': year, 'llm': year_llm_bigram_frequency_all + year_llm_trigram_frequency_all})\n",
    "    focus_data_all_authors.append({'Year': year, 'non_llm': year_non_llm_bigram_frequency + year_non_llm_trigram_frequency})\n",
    "\n",
    "# Step 2: Create DataFrames to store the data\n",
    "focus_df_top_authors = pd.DataFrame(focus_data_top_authors)\n",
    "focus_df_all_authors = pd.DataFrame(focus_data_all_authors)\n",
    "\n",
    "# Step 3: Plot the line graph using Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add a line for top 20 authors\n",
    "fig.add_trace(go.Scatter(x=focus_df_top_authors['Year'], y=focus_df_top_authors['llm'],\n",
    "                         mode='lines+markers', name='llm'))\n",
    "\n",
    "# Add a line for all authors\n",
    "fig.add_trace(go.Scatter(x=focus_df_all_authors['Year'], y=focus_df_all_authors['non_llm'],\n",
    "                         mode='lines+markers', name='non_llm'))\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(title='Focus on Large Language Models Over the Years',\n",
    "                  xaxis_title='Year', yaxis_title='Frequency',\n",
    "                  legend=dict(x=0, y=1))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "606688f6-8b62-4edf-9cbd-3d0fddd6c803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_63.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of years for analysis\n",
    "years = range(2017, 2024)  # Adjust the range as needed\n",
    "\n",
    "# Initialize empty lists to store data\n",
    "bigram_data = []\n",
    "\n",
    "# Loop through each year and calculate the sum of LLM bigram frequencies\n",
    "for year in years:\n",
    "    # Filter the LLM bigram DataFrame for the current year\n",
    "    llm_bigrams_year = llm_bigram_df[llm_bigram_df['year'] == year]\n",
    "    \n",
    "    # Calculate the sum of LLM bigram frequencies for the current year\n",
    "    llm_bigram_sum = llm_bigrams_year['frequency'].sum()\n",
    "    \n",
    "    # Get the top 5 non-LLM bigrams for the current year\n",
    "    top_non_llm_bigrams = bigram_df[bigram_df['year'] == year].nlargest(5, 'frequency')\n",
    "    \n",
    "    # Convert the Pandas Series to a list of strings\n",
    "    top_non_llm_bigram_names = top_non_llm_bigrams['word'].tolist()\n",
    "    \n",
    "    # Append data for the current year to the list\n",
    "    bigram_data.append({\n",
    "        'Year': year,\n",
    "        'LLM Bigram Sum': llm_bigram_sum,\n",
    "        'Top 5 Non-LLM Bigrams': top_non_llm_bigram_names,\n",
    "        'Top 5 Non-LLM Bigram Frequencies': top_non_llm_bigrams['frequency'].tolist()\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "bigram_evolution_df = pd.DataFrame(bigram_data)\n",
    "\n",
    "# Create a Plotly line graph for the evolution of LLM bigrams and top 5 non-LLM bigrams\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add lines for top 5 non-LLM bigrams\n",
    "for i in range(5):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=bigram_evolution_df['Year'],\n",
    "        y=bigram_evolution_df['Top 5 Non-LLM Bigram Frequencies'].apply(lambda x: x[i]),\n",
    "        mode='lines+markers',\n",
    "        name=top_non_llm_bigram_names[i]\n",
    "    ))\n",
    "\n",
    "# Add a line for LLM bigram sum\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=bigram_evolution_df['Year'],\n",
    "    y=bigram_evolution_df['LLM Bigram Sum'],\n",
    "    mode='lines+markers',\n",
    "    name='LLM'\n",
    "))\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    title='Evolution of Bigrams over year',\n",
    "    xaxis_title='Year',\n",
    "    yaxis_title='Frequency',\n",
    "    legend=dict(x=0, y=1)\n",
    ")\n",
    "\n",
    "# Show the graph\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "53a653db-b0cc-4502-84e1-0ed926f38775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_64.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of years for analysis\n",
    "years = range(2017, 2024)  # Adjust the range as needed\n",
    "\n",
    "# Initialize empty lists to store data\n",
    "trigram_data = []\n",
    "\n",
    "# Loop through each year and calculate the sum of LLM bigram frequencies\n",
    "for year in years:\n",
    "    # Filter the LLM bigram DataFrame for the current year\n",
    "    llm_trigrams_year = llm_trigram_df[llm_trigram_df['year'] == year]\n",
    "    \n",
    "    # Calculate the sum of LLM bigram frequencies for the current year\n",
    "    llm_trigram_sum = llm_trigrams_year['frequency'].sum()\n",
    "    \n",
    "    # Get the top 5 non-LLM bigrams for the current year\n",
    "    top_non_llm_trigrams = trigram_df[trigram_df['year'] == year].nlargest(5, 'frequency')\n",
    "    \n",
    "    # Convert the Pandas Series to a list of strings\n",
    "    top_non_llm_trigram_names = top_non_llm_trigrams['word'].tolist()\n",
    "    \n",
    "    # Append data for the current year to the list\n",
    "    trigram_data.append({\n",
    "        'Year': year,\n",
    "        'LLM Trigram Sum': llm_trigram_sum,\n",
    "        'Top 5 Non-LLM Trigrams': top_non_llm_trigram_names,\n",
    "        'Top 5 Non-LLM Trigram Frequencies': top_non_llm_trigrams['frequency'].tolist()\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "trigram_evolution_df = pd.DataFrame(trigram_data)\n",
    "\n",
    "# Create a Plotly line graph for the evolution of LLM bigrams and top 5 non-LLM bigrams\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add lines for top 5 non-LLM bigrams\n",
    "for i in range(5):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=trigram_evolution_df['Year'],\n",
    "        y=trigram_evolution_df['Top 5 Non-LLM Trigram Frequencies'].apply(lambda x: x[i]),\n",
    "        mode='lines+markers',\n",
    "        name=top_non_llm_trigram_names[i]\n",
    "    ))\n",
    "\n",
    "# Add a line for LLM bigram sum\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=trigram_evolution_df['Year'],\n",
    "    y=trigram_evolution_df['LLM Trigram Sum'],\n",
    "    mode='lines+markers',\n",
    "    name='LLM'\n",
    "))\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    title='Evolution of Trigrams over year',\n",
    "    xaxis_title='Year',\n",
    "    yaxis_title='Frequency',\n",
    "    legend=dict(x=0, y=1)\n",
    ")\n",
    "\n",
    "# Show the graph\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707f92be-5608-407c-90d5-45c199bf7788",
   "metadata": {},
   "source": [
    "# Senior vs Junior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0039cca0-e28c-4ea8-8f31-e8cb1d955b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senior Authors:\n",
      "               author  Number of Papers Published Author Category\n",
      "0            Zhang Y.                          49   Senior Author\n",
      "1          Choi Yejin                          40   Senior Author\n",
      "2        Gao Jianfeng                          38   Senior Author\n",
      "3               Li Y.                          35   Senior Author\n",
      "4         Liu Zhiyuan                          34   Senior Author\n",
      "5           Lin Jimmy                          33   Senior Author\n",
      "6            Liu Yang                          33   Senior Author\n",
      "7           Zhang Yue                          33   Senior Author\n",
      "8           Jiang Xin                          33   Senior Author\n",
      "9       Xiong Caiming                          30   Senior Author\n",
      "10      Smith Noah A.                          30   Senior Author\n",
      "11          Ren Xiang                          30   Senior Author\n",
      "12           Li Xiang                          29   Senior Author\n",
      "13    Schütze Hinrich                          29   Senior Author\n",
      "14        Sun Maosong                          29   Senior Author\n",
      "15  Wang William Yang                          29   Senior Author\n",
      "16           Liu Ting                          29   Senior Author\n",
      "17        Liang Percy                          27   Senior Author\n",
      "18            Dong Li                          27   Senior Author\n",
      "19            Wang J.                          27   Senior Author\n",
      "20           Zhou Jie                          27   Senior Author\n",
      "21            Wang Y.                          26   Senior Author\n",
      "\n",
      "Junior Authors:\n",
      "             author  Number of Papers Published Author Category\n",
      "0  Zettlemoyer Luke                          43   Junior Author\n",
      "1        Qiu Xipeng                          41   Junior Author\n",
      "2          Wei Furu                          40   Junior Author\n",
      "3           Liu Qun                          33   Junior Author\n",
      "4    Huang Xuanjing                          31   Junior Author\n",
      "5         Huang Fei                          29   Junior Author\n",
      "6          Duan Nan                          28   Junior Author\n",
      "7     Joshi Raviraj                          28   Junior Author\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrames from the sample data\n",
    "senior_junior_authors = pd.DataFrame(llm_top_authors)\n",
    "papers_df = pd.DataFrame(papers)\n",
    "\n",
    "# Calculate the current year\n",
    "current_year = datetime.now().year\n",
    "\n",
    "# Convert the 'update_date' column to datetime and handle invalid or missing dates\n",
    "def convert_to_datetime(date_str):\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "    except (TypeError, ValueError):\n",
    "        return pd.NaT  # Return a Not-a-Time (NaT) for invalid or missing dates\n",
    "\n",
    "papers_df['update_date'] = papers_df['update_date'].apply(convert_to_datetime)\n",
    "\n",
    "# Define a function to categorize authors as senior or junior\n",
    "def categorize_author(author):\n",
    "    author_papers = papers_df[papers_df['authors'].apply(lambda x: author in x)]\n",
    "    \n",
    "    # Handle the case where there are no papers for the author\n",
    "    if author_papers.empty:\n",
    "        return 'Unknown Author'\n",
    "    \n",
    "    latest_update_year = min(author_papers['update_date'].dt.year, default=current_year)\n",
    "    if current_year - latest_update_year > 8:\n",
    "        return 'Senior Author'\n",
    "    else:\n",
    "        return 'Junior Author'\n",
    "\n",
    "# Apply the categorize_author function to the top authors DataFrame\n",
    "senior_junior_authors['Author Category'] = senior_junior_authors['author'].apply(categorize_author)\n",
    "\n",
    "# Separate the senior and junior authors into two dataframes\n",
    "senior_authors_df = senior_junior_authors[senior_junior_authors['Author Category'] == 'Senior Author']\n",
    "junior_authors_df = senior_junior_authors[senior_junior_authors['Author Category'] == 'Junior Author']\n",
    "\n",
    "senior_authors_df = senior_authors_df.reset_index(drop=True)\n",
    "junior_authors_df = junior_authors_df.reset_index(drop=True)\n",
    "# Display the results\n",
    "print(\"Senior Authors:\")\n",
    "print(senior_authors_df)\n",
    "\n",
    "print(\"\\nJunior Authors:\")\n",
    "print(junior_authors_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf53d88a-56fa-46c8-ad3a-bbb88169c7fc",
   "metadata": {},
   "source": [
    "## Senior Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c17e0a5b-f173-47c6-b93f-9babab1aa45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 371718/371718 [15:45<00:00, 393.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40923453\n",
      "40551735\n",
      "17289159\n",
      "34788810\n",
      "Bigram DataFrame:\n",
      "          frequency  year                            word\n",
      "16148173       2527  2021             deep neural network\n",
      "10746521       2507  2020             deep neural network\n",
      "6409682        2239  2019             deep neural network\n",
      "2784630        2234  2018    convolutional neural network\n",
      "22237000       2200  2022             deep neural network\n",
      "...             ...   ...                             ...\n",
      "23145099         21  2022          method achieve parable\n",
      "23147243         21  2022            neural network multi\n",
      "23149895         21  2022                           n 2 n\n",
      "16878118         21  2021  theoretical analysis empirical\n",
      "2950604          21  2018          pose estimation method\n",
      "\n",
      "[23563 rows x 3 columns]\n",
      "\n",
      " Trigram DataFrame:\n",
      "          frequency  year                            word\n",
      "16148173       2527  2021             deep neural network\n",
      "10746521       2507  2020             deep neural network\n",
      "6409682        2239  2019             deep neural network\n",
      "2784630        2234  2018    convolutional neural network\n",
      "22237000       2200  2022             deep neural network\n",
      "...             ...   ...                             ...\n",
      "23145099         21  2022          method achieve parable\n",
      "23147243         21  2022            neural network multi\n",
      "23149895         21  2022                           n 2 n\n",
      "16878118         21  2021  theoretical analysis empirical\n",
      "2950604          21  2018          pose estimation method\n",
      "\n",
      "[23563 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "senior_authors = senior_authors_df['author']\n",
    "non_llm_publications = non_llm_papers[non_llm_papers['authors'].apply(lambda authors: any(author for author in senior_authors))]\n",
    "\n",
    "# SUCCESS Initialize lists to store bigrams and trigrams with their years\n",
    "bigram_data = []\n",
    "trigram_data = []\n",
    "\n",
    "# Function to extract ngrams from text\n",
    "def extract_ngrams(text, n, year):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    n_grams = ngrams(tokens, n)\n",
    "    return [(year, ' '.join(gram)) for gram in n_grams]\n",
    "\n",
    "# Iterate over the DataFrame with tqdm for progress monitoring\n",
    "for _, row in tqdm(non_llm_publications.iterrows(), total=len(non_llm_publications)):\n",
    "    title_abstract = row['processed_titles_abstracts']\n",
    "    year = row['year']\n",
    "    \n",
    "    # Extract bigrams and trigrams\n",
    "    bigram_data.extend(extract_ngrams(title_abstract, 2, year))\n",
    "    trigram_data.extend(extract_ngrams(title_abstract, 3, year))\n",
    "\n",
    "\n",
    "print(len(bigram_data))\n",
    "print(len(trigram_data))\n",
    "\n",
    "# Calculate the frequency of bigrams and trigrams with years\n",
    "bigram_freq = Counter(bigram_data)\n",
    "trigram_freq = Counter(trigram_data)\n",
    "print(len(bigram_freq))\n",
    "print(len(trigram_freq))\n",
    "\n",
    "# Create DataFrames for bigrams and trigrams with years\n",
    "senior_authors_bigram_df = pd.DataFrame(list(bigram_freq.items()), columns=['(year, word)', 'frequency'])\n",
    "senior_authors_bigram_df[['year', 'word']] = pd.DataFrame(senior_authors_bigram_df['(year, word)'].tolist(), index=senior_authors_bigram_df.index)\n",
    "senior_authors_bigram_df.drop(columns=['(year, word)'], inplace=True)\n",
    "\n",
    "senior_authors_trigram_df = pd.DataFrame(list(trigram_freq.items()), columns=['(year, word)', 'frequency'])\n",
    "senior_authors_trigram_df[['year', 'word']] = pd.DataFrame(senior_authors_trigram_df['(year, word)'].tolist(), index=senior_authors_trigram_df.index)\n",
    "senior_authors_trigram_df.drop(columns=['(year, word)'], inplace=True)\n",
    "\n",
    "\n",
    "# Sort the bigram DataFrame by frequency in descending order\n",
    "senior_authors_bigram_df = senior_authors_bigram_df[senior_authors_bigram_df['frequency'] > 20].sort_values(by='frequency', ascending=False)\n",
    "\n",
    "# Sort the trigram DataFrame by frequency in descending order\n",
    "senior_authors_trigram_df = senior_authors_trigram_df[senior_authors_trigram_df['frequency'] > 20].sort_values(by='frequency', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(\"Bigram DataFrame:\")\n",
    "print(senior_authors_trigram_df)\n",
    "\n",
    "print(\"\\n Trigram DataFrame:\")\n",
    "print(senior_authors_trigram_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fe3374fe-5815-442f-8724-c6c770c32995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 624/624 [00:53<00:00, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senior Authors llm Bigram DataFrame:\n",
      "       frequency  year                 word\n",
      "26450        234  2023       large language\n",
      "26324        209  2023       language model\n",
      "26451        139  2023      language models\n",
      "18136        116  2022       language model\n",
      "26336         85  2023     natural language\n",
      "...          ...   ...                  ...\n",
      "20913          1  2022          base source\n",
      "20914          1  2022     source exemplars\n",
      "20915          1  2022  exemplars challenge\n",
      "20916          1  2022   challenge exemplar\n",
      "58637          1  2019       right reserved\n",
      "\n",
      "[58638 rows x 3 columns]\n",
      "\n",
      " Senior Authors llm Trigram DataFrame:\n",
      "       frequency  year                              word\n",
      "30370        130  2023              large language model\n",
      "30322        100  2023             large language models\n",
      "30495         73  2023               language model llms\n",
      "21032         40  2022              pre trained language\n",
      "6377          34  2020              pre trained language\n",
      "...          ...   ...                               ...\n",
      "23514          1  2022  configuration training objective\n",
      "23515          1  2022    training objective transformer\n",
      "23516          1  2022       objective transformer based\n",
      "23517          1  2022           transformer based model\n",
      "68953          1  2019           business right reserved\n",
      "\n",
      "[68954 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "senior_authors = senior_authors_df['author']\n",
    "senior_authors_llm_publications = llm_papers[llm_papers['authors'].apply(lambda authors: any(author in authors for author in senior_authors))]\n",
    "\n",
    "# SUCCESS Initialize lists to store bigrams and trigrams with their years\n",
    "senior_authors_llm_bigram_data = []\n",
    "senior_authors_llm_trigram_data = []\n",
    "\n",
    "# Function to extract ngrams from text\n",
    "def extract_ngrams(text, n, year):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    n_grams = ngrams(tokens, n)\n",
    "    return [(year, ' '.join(gram)) for gram in n_grams]\n",
    "\n",
    "# Iterate over the DataFrame with tqdm for progress monitoring\n",
    "for _, row in tqdm(senior_authors_llm_publications.iterrows(), total=len(senior_authors_llm_publications)):\n",
    "    title_abstract = row['processed_titles_abstracts']\n",
    "    year = row['year']\n",
    "    \n",
    "    # Extract bigrams and trigrams\n",
    "    senior_authors_llm_bigram_data.extend(extract_ngrams(title_abstract, 2, year))\n",
    "    senior_authors_llm_trigram_data.extend(extract_ngrams(title_abstract, 3, year))\n",
    "\n",
    "# Calculate the frequency of bigrams and trigrams with years\n",
    "senior_authors_llm_bigram_freq = Counter(senior_authors_llm_bigram_data)\n",
    "senior_authors_llm_trigram_freq = Counter(senior_authors_llm_trigram_data)\n",
    "\n",
    "# Create DataFrames for bigrams and trigrams with years\n",
    "senior_authors_llm_bigram_df = pd.DataFrame(list(senior_authors_llm_bigram_freq.items()), columns=['(year, word)', 'frequency'])\n",
    "senior_authors_llm_bigram_df[['year', 'word']] = pd.DataFrame(senior_authors_llm_bigram_df['(year, word)'].tolist(), index=senior_authors_llm_bigram_df.index)\n",
    "senior_authors_llm_bigram_df.drop(columns=['(year, word)'], inplace=True)\n",
    "\n",
    "senior_authors_llm_trigram_df = pd.DataFrame(list(senior_authors_llm_trigram_freq.items()), columns=['(year, word)', 'frequency'])\n",
    "senior_authors_llm_trigram_df[['year', 'word']] = pd.DataFrame(senior_authors_llm_trigram_df['(year, word)'].tolist(), index=senior_authors_llm_trigram_df.index)\n",
    "senior_authors_llm_trigram_df.drop(columns=['(year, word)'], inplace=True)\n",
    "\n",
    "\n",
    "# Sort the bigram DataFrame by frequency in descending order\n",
    "senior_authors_llm_bigram_df = senior_authors_llm_bigram_df.sort_values(by='frequency', ascending=False)\n",
    "\n",
    "# Sort the trigram DataFrame by frequency in descending order\n",
    "senior_authors_llm_trigram_df = senior_authors_llm_trigram_df.sort_values(by='frequency', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(\"Senior Authors llm Bigram DataFrame:\")\n",
    "print(senior_authors_llm_bigram_df)\n",
    "\n",
    "print(\"\\n Senior Authors llm Trigram DataFrame:\")\n",
    "print(senior_authors_llm_trigram_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fbe29c3c-0e2e-4f36-9bf6-a7dec06c1d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_68.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of years for analysis\n",
    "years = range(2017, 2024)  # Adjust the range as needed\n",
    "\n",
    "# Initialize empty lists to store data\n",
    "bigram_data = []\n",
    "\n",
    "# Loop through each year and calculate the sum of LLM bigram frequencies\n",
    "for year in years:\n",
    "    # Filter the LLM bigram DataFrame for the current year\n",
    "    llm_bigrams_year = senior_authors_llm_bigram_df[senior_authors_llm_bigram_df['year'] == year]\n",
    "    \n",
    "    # Calculate the sum of LLM bigram frequencies for the current year\n",
    "    llm_bigram_sum = llm_bigrams_year['frequency'].sum()\n",
    "    \n",
    "    # Get the top 5 non-LLM bigrams for the current year\n",
    "    top_non_llm_bigrams = senior_authors_bigram_df[senior_authors_bigram_df['year'] == year].nlargest(5, 'frequency')\n",
    "    \n",
    "    # Convert the Pandas Series to a list of strings\n",
    "    top_non_llm_bigram_names = top_non_llm_bigrams['word'].tolist()\n",
    "    \n",
    "    # Append data for the current year to the list\n",
    "    bigram_data.append({\n",
    "        'Year': year,\n",
    "        'LLM Bigram Sum': llm_bigram_sum,\n",
    "        'Top 5 Non-LLM Bigrams': top_non_llm_bigram_names,\n",
    "        'Top 5 Non-LLM Bigram Frequencies': top_non_llm_bigrams['frequency'].tolist()\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "bigram_evolution_df = pd.DataFrame(bigram_data)\n",
    "\n",
    "# Create a Plotly line graph for the evolution of LLM bigrams and top 5 non-LLM bigrams\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add lines for top 5 non-LLM bigrams\n",
    "for i in range(5):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=bigram_evolution_df['Year'],\n",
    "        y=bigram_evolution_df['Top 5 Non-LLM Bigram Frequencies'].apply(lambda x: x[i]),\n",
    "        mode='lines+markers',\n",
    "        name=top_non_llm_bigram_names[i]\n",
    "    ))\n",
    "\n",
    "# Add a line for LLM bigram sum\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=bigram_evolution_df['Year'],\n",
    "    y=bigram_evolution_df['LLM Bigram Sum'],\n",
    "    mode='lines+markers',\n",
    "    name='LLM'\n",
    "))\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    title='Evolution of Bigrams over year - Senior Authors',\n",
    "    xaxis_title='Year',\n",
    "    yaxis_title='Frequency',\n",
    "    legend=dict(x=0, y=1)\n",
    ")\n",
    "\n",
    "# Show the graph\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "98725578-a2f1-44c8-929e-d68a461cf27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_69.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of years for analysis\n",
    "years = range(2017, 2024)  # Adjust the range as needed\n",
    "\n",
    "# Initialize empty lists to store data\n",
    "trigram_data = []\n",
    "\n",
    "# Loop through each year and calculate the sum of LLM bigram frequencies\n",
    "for year in years:\n",
    "    # Filter the LLM bigram DataFrame for the current year\n",
    "    llm_trigrams_year = senior_authors_llm_trigram_df[senior_authors_llm_trigram_df['year'] == year]\n",
    "    \n",
    "    # Calculate the sum of LLM bigram frequencies for the current year\n",
    "    llm_trigram_sum = llm_trigrams_year['frequency'].sum()\n",
    "    \n",
    "    # Get the top 5 non-LLM bigrams for the current year\n",
    "    top_non_llm_trigrams = senior_authors_trigram_df[senior_authors_trigram_df['year'] == year].nlargest(5, 'frequency')\n",
    "    \n",
    "    # Convert the Pandas Series to a list of strings\n",
    "    top_non_llm_trigram_names = top_non_llm_trigrams['word'].tolist()\n",
    "    \n",
    "    # Append data for the current year to the list\n",
    "    trigram_data.append({\n",
    "        'Year': year,\n",
    "        'LLM Trigram Sum': llm_trigram_sum,\n",
    "        'Top 5 Non-LLM Trigrams': top_non_llm_trigram_names,\n",
    "        'Top 5 Non-LLM Trigram Frequencies': top_non_llm_trigrams['frequency'].tolist()\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "trigram_evolution_df = pd.DataFrame(trigram_data)\n",
    "\n",
    "# Create a Plotly line graph for the evolution of LLM bigrams and top 5 non-LLM bigrams\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add lines for top 5 non-LLM bigrams\n",
    "for i in range(5):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=trigram_evolution_df['Year'],\n",
    "        y=trigram_evolution_df['Top 5 Non-LLM Trigram Frequencies'].apply(lambda x: x[i]),\n",
    "        mode='lines+markers',\n",
    "        name=top_non_llm_trigram_names[i]\n",
    "    ))\n",
    "\n",
    "# Add a line for LLM bigram sum\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=trigram_evolution_df['Year'],\n",
    "    y=trigram_evolution_df['LLM Trigram Sum'],\n",
    "    mode='lines+markers',\n",
    "    name='LLM'\n",
    "))\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    title='Evolution of Trigrams over year - Senior Authors',\n",
    "    xaxis_title='Year',\n",
    "    yaxis_title='Frequency',\n",
    "    legend=dict(x=0, y=1)\n",
    ")\n",
    "\n",
    "# Show the graph\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fad1870-2aa8-4a41-b6d8-0e224cfe8849",
   "metadata": {},
   "source": [
    "## Junior Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ccaa01e-bf7b-431a-84ff-5003e28f6c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 371718/371718 [06:44<00:00, 918.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40923453\n",
      "40551735\n",
      "17289159\n",
      "34788810\n",
      "Junior Bigram DataFrame:\n",
      "          frequency  year                            word\n",
      "16148173       2527  2021             deep neural network\n",
      "10746521       2507  2020             deep neural network\n",
      "6409682        2239  2019             deep neural network\n",
      "2784630        2234  2018    convolutional neural network\n",
      "22237000       2200  2022             deep neural network\n",
      "...             ...   ...                             ...\n",
      "23145099         21  2022          method achieve parable\n",
      "23147243         21  2022            neural network multi\n",
      "23149895         21  2022                           n 2 n\n",
      "16878118         21  2021  theoretical analysis empirical\n",
      "2950604          21  2018          pose estimation method\n",
      "\n",
      "[23563 rows x 3 columns]\n",
      "\n",
      " Junior Trigram DataFrame:\n",
      "          frequency  year                            word\n",
      "16148173       2527  2021             deep neural network\n",
      "10746521       2507  2020             deep neural network\n",
      "6409682        2239  2019             deep neural network\n",
      "2784630        2234  2018    convolutional neural network\n",
      "22237000       2200  2022             deep neural network\n",
      "...             ...   ...                             ...\n",
      "23145099         21  2022          method achieve parable\n",
      "23147243         21  2022            neural network multi\n",
      "23149895         21  2022                           n 2 n\n",
      "16878118         21  2021  theoretical analysis empirical\n",
      "2950604          21  2018          pose estimation method\n",
      "\n",
      "[23563 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "junior_authors = junior_authors_df['author']\n",
    "non_llm_publications = non_llm_papers[non_llm_papers['authors'].apply(lambda authors: any(author for author in junior_authors))]\n",
    "\n",
    "# SUCCESS Initialize lists to store bigrams and trigrams with their years\n",
    "bigram_data = []\n",
    "trigram_data = []\n",
    "\n",
    "# Function to extract ngrams from text\n",
    "def extract_ngrams(text, n, year):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    n_grams = ngrams(tokens, n)\n",
    "    return [(year, ' '.join(gram)) for gram in n_grams]\n",
    "\n",
    "# Iterate over the DataFrame with tqdm for progress monitoring\n",
    "for _, row in tqdm(non_llm_publications.iterrows(), total=len(non_llm_publications)):\n",
    "    title_abstract = row['processed_titles_abstracts']\n",
    "    year = row['year']\n",
    "    \n",
    "    # Extract bigrams and trigrams\n",
    "    bigram_data.extend(extract_ngrams(title_abstract, 2, year))\n",
    "    trigram_data.extend(extract_ngrams(title_abstract, 3, year))\n",
    "\n",
    "\n",
    "print(len(bigram_data))\n",
    "print(len(trigram_data))\n",
    "\n",
    "# Calculate the frequency of bigrams and trigrams with years\n",
    "bigram_freq = Counter(bigram_data)\n",
    "trigram_freq = Counter(trigram_data)\n",
    "print(len(bigram_freq))\n",
    "print(len(trigram_freq))\n",
    "\n",
    "# Create DataFrames for bigrams and trigrams with years\n",
    "junior_authors_bigram_df = pd.DataFrame(list(bigram_freq.items()), columns=['(year, word)', 'frequency'])\n",
    "junior_authors_bigram_df[['year', 'word']] = pd.DataFrame(junior_authors_bigram_df['(year, word)'].tolist(), index=junior_authors_bigram_df.index)\n",
    "junior_authors_bigram_df.drop(columns=['(year, word)'], inplace=True)\n",
    "\n",
    "junior_authors_trigram_df = pd.DataFrame(list(trigram_freq.items()), columns=['(year, word)', 'frequency'])\n",
    "junior_authors_trigram_df[['year', 'word']] = pd.DataFrame(junior_authors_trigram_df['(year, word)'].tolist(), index=junior_authors_trigram_df.index)\n",
    "junior_authors_trigram_df.drop(columns=['(year, word)'], inplace=True)\n",
    "\n",
    "\n",
    "# Sort the bigram DataFrame by frequency in descending order\n",
    "junior_authors_bigram_df = junior_authors_bigram_df[junior_authors_bigram_df['frequency'] > 20].sort_values(by='frequency', ascending=False)\n",
    "\n",
    "# Sort the trigram DataFrame by frequency in descending order\n",
    "junior_authors_trigram_df = junior_authors_trigram_df[junior_authors_trigram_df['frequency'] > 20].sort_values(by='frequency', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(\"Junior Bigram DataFrame:\")\n",
    "print(junior_authors_trigram_df)\n",
    "\n",
    "print(\"\\n Junior Trigram DataFrame:\")\n",
    "print(junior_authors_trigram_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "40117d96-bfac-49ba-a8b0-c933f700be64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 254/254 [00:56<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senior Authors llm Bigram DataFrame:\n",
      "       frequency  year                 word\n",
      "14863        121  2023       large language\n",
      "14798         98  2023       language model\n",
      "14790         75  2023      language models\n",
      "5595          41  2021          pre trained\n",
      "9311          40  2022       language model\n",
      "...          ...   ...                  ...\n",
      "8454           1  2021         recent years\n",
      "8453           1  2021        models recent\n",
      "8452           1  2021  reusable pretrained\n",
      "8451           1  2021   bert2bert reusable\n",
      "23975          1  2023          nlp systems\n",
      "\n",
      "[23976 rows x 3 columns]\n",
      "\n",
      " Senior Authors llm Trigram DataFrame:\n",
      "       frequency  year                    word\n",
      "17096         68  2023    large language model\n",
      "17037         53  2023   large language models\n",
      "17097         31  2023     language model llms\n",
      "6491          18  2021    pre trained language\n",
      "11309         16  2022    large language model\n",
      "...          ...   ...                     ...\n",
      "9407           1  2021     better benefit shot\n",
      "9406           1  2021   tuning better benefit\n",
      "9405           1  2021      fine tuning better\n",
      "9402           1  2021  objective pre training\n",
      "27717          1  2023  capability nlp systems\n",
      "\n",
      "[27718 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "junior_authors = junior_authors_df['author']\n",
    "junior_authors_llm_publications = llm_papers[llm_papers['authors'].apply(lambda authors: any(author in authors for author in junior_authors))]\n",
    "\n",
    "# SUCCESS Initialize lists to store bigrams and trigrams with their years\n",
    "junior_authors_llm_bigram_data = []\n",
    "junior_authors_llm_trigram_data = []\n",
    "\n",
    "# Function to extract ngrams from text\n",
    "def extract_ngrams(text, n, year):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    n_grams = ngrams(tokens, n)\n",
    "    return [(year, ' '.join(gram)) for gram in n_grams]\n",
    "\n",
    "# Iterate over the DataFrame with tqdm for progress monitoring\n",
    "for _, row in tqdm(junior_authors_llm_publications.iterrows(), total=len(junior_authors_llm_publications)):\n",
    "    title_abstract = row['processed_titles_abstracts']\n",
    "    year = row['year']\n",
    "    \n",
    "    # Extract bigrams and trigrams\n",
    "    junior_authors_llm_bigram_data.extend(extract_ngrams(title_abstract, 2, year))\n",
    "    junior_authors_llm_trigram_data.extend(extract_ngrams(title_abstract, 3, year))\n",
    "\n",
    "# Calculate the frequency of bigrams and trigrams with years\n",
    "junior_authors_llm_bigram_freq = Counter(junior_authors_llm_bigram_data)\n",
    "junior_authors_llm_trigram_freq = Counter(junior_authors_llm_trigram_data)\n",
    "\n",
    "# Create DataFrames for bigrams and trigrams with years\n",
    "junior_authors_llm_bigram_df = pd.DataFrame(list(junior_authors_llm_bigram_freq.items()), columns=['(year, word)', 'frequency'])\n",
    "junior_authors_llm_bigram_df[['year', 'word']] = pd.DataFrame(junior_authors_llm_bigram_df['(year, word)'].tolist(), index=junior_authors_llm_bigram_df.index)\n",
    "junior_authors_llm_bigram_df.drop(columns=['(year, word)'], inplace=True)\n",
    "\n",
    "junior_authors_llm_trigram_df = pd.DataFrame(list(junior_authors_llm_trigram_freq.items()), columns=['(year, word)', 'frequency'])\n",
    "junior_authors_llm_trigram_df[['year', 'word']] = pd.DataFrame(junior_authors_llm_trigram_df['(year, word)'].tolist(), index=junior_authors_llm_trigram_df.index)\n",
    "junior_authors_llm_trigram_df.drop(columns=['(year, word)'], inplace=True)\n",
    "\n",
    "\n",
    "# Sort the bigram DataFrame by frequency in descending order\n",
    "junior_authors_llm_bigram_df = junior_authors_llm_bigram_df.sort_values(by='frequency', ascending=False)\n",
    "\n",
    "# Sort the trigram DataFrame by frequency in descending order\n",
    "junior_authors_llm_trigram_df = junior_authors_llm_trigram_df.sort_values(by='frequency', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(\"Senior Authors llm Bigram DataFrame:\")\n",
    "print(junior_authors_llm_bigram_df)\n",
    "\n",
    "print(\"\\n Senior Authors llm Trigram DataFrame:\")\n",
    "print(junior_authors_llm_trigram_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3eb08753-beed-4369-84a3-e5a0a7cb1d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_72.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of years for analysis\n",
    "years = range(2017, 2024)  # Adjust the range as needed\n",
    "\n",
    "# Initialize empty lists to store data\n",
    "bigram_data = []\n",
    "\n",
    "# Loop through each year and calculate the sum of LLM bigram frequencies\n",
    "for year in years:\n",
    "    # Filter the LLM bigram DataFrame for the current year\n",
    "    llm_bigrams_year = junior_authors_llm_bigram_df[junior_authors_llm_bigram_df['year'] == year]\n",
    "    \n",
    "    # Calculate the sum of LLM bigram frequencies for the current year\n",
    "    llm_bigram_sum = llm_bigrams_year['frequency'].sum()\n",
    "    \n",
    "    # Get the top 5 non-LLM bigrams for the current year\n",
    "    top_non_llm_bigrams = junior_authors_bigram_df[junior_authors_bigram_df['year'] == year].nlargest(5, 'frequency')\n",
    "    \n",
    "    # Convert the Pandas Series to a list of strings\n",
    "    top_non_llm_bigram_names = top_non_llm_bigrams['word'].tolist()\n",
    "    \n",
    "    # Append data for the current year to the list\n",
    "    bigram_data.append({\n",
    "        'Year': year,\n",
    "        'LLM Bigram Sum': llm_bigram_sum,\n",
    "        'Top 5 Non-LLM Bigrams': top_non_llm_bigram_names,\n",
    "        'Top 5 Non-LLM Bigram Frequencies': top_non_llm_bigrams['frequency'].tolist()\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "bigram_evolution_df = pd.DataFrame(bigram_data)\n",
    "\n",
    "# Create a Plotly line graph for the evolution of LLM bigrams and top 5 non-LLM bigrams\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add lines for top 5 non-LLM bigrams\n",
    "for i in range(5):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=bigram_evolution_df['Year'],\n",
    "        y=bigram_evolution_df['Top 5 Non-LLM Bigram Frequencies'].apply(lambda x: x[i]),\n",
    "        mode='lines+markers',\n",
    "        name=top_non_llm_bigram_names[i]\n",
    "    ))\n",
    "\n",
    "# Add a line for LLM bigram sum\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=bigram_evolution_df['Year'],\n",
    "    y=bigram_evolution_df['LLM Bigram Sum'],\n",
    "    mode='lines+markers',\n",
    "    name='LLM'\n",
    "))\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    title='Evolution of Bigrams over year - Junior Authors',\n",
    "    xaxis_title='Year',\n",
    "    yaxis_title='Frequency',\n",
    "    legend=dict(x=0, y=1)\n",
    ")\n",
    "\n",
    "# Show the graph\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6f923ad2-5d82-48ea-99a0-fe9cea0d2ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_73.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of years for analysis\n",
    "years = range(2017, 2024)  # Adjust the range as needed\n",
    "\n",
    "# Initialize empty lists to store data\n",
    "trigram_data = []\n",
    "\n",
    "# Loop through each year and calculate the sum of LLM bigram frequencies\n",
    "for year in years:\n",
    "    # Filter the LLM bigram DataFrame for the current year\n",
    "    llm_trigrams_year = junior_authors_llm_trigram_df[junior_authors_llm_trigram_df['year'] == year]\n",
    "    \n",
    "    # Calculate the sum of LLM bigram frequencies for the current year\n",
    "    llm_trigram_sum = llm_trigrams_year['frequency'].sum()\n",
    "    \n",
    "    # Get the top 5 non-LLM bigrams for the current year\n",
    "    top_non_llm_trigrams = junior_authors_trigram_df[junior_authors_trigram_df['year'] == year].nlargest(5, 'frequency')\n",
    "    \n",
    "    # Convert the Pandas Series to a list of strings\n",
    "    top_non_llm_trigram_names = top_non_llm_trigrams['word'].tolist()\n",
    "    \n",
    "    # Append data for the current year to the list\n",
    "    trigram_data.append({\n",
    "        'Year': year,\n",
    "        'LLM Trigram Sum': llm_trigram_sum,\n",
    "        'Top 5 Non-LLM Trigrams': top_non_llm_trigram_names,\n",
    "        'Top 5 Non-LLM Trigram Frequencies': top_non_llm_trigrams['frequency'].tolist()\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "trigram_evolution_df = pd.DataFrame(trigram_data)\n",
    "\n",
    "# Create a Plotly line graph for the evolution of LLM bigrams and top 5 non-LLM bigrams\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add lines for top 5 non-LLM bigrams\n",
    "for i in range(5):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=trigram_evolution_df['Year'],\n",
    "        y=trigram_evolution_df['Top 5 Non-LLM Trigram Frequencies'].apply(lambda x: x[i]),\n",
    "        mode='lines+markers',\n",
    "        name=top_non_llm_trigram_names[i]\n",
    "    ))\n",
    "\n",
    "# Add a line for LLM bigram sum\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=trigram_evolution_df['Year'],\n",
    "    y=trigram_evolution_df['LLM Trigram Sum'],\n",
    "    mode='lines+markers',\n",
    "    name='LLM'\n",
    "))\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    title='Evolution of Trigrams over year - Junior Authors',\n",
    "    xaxis_title='Year',\n",
    "    yaxis_title='Frequency',\n",
    "    legend=dict(x=0, y=1)\n",
    ")\n",
    "\n",
    "# Show the graph\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2d09a2-a4ee-4fdc-8a24-104dbd8c4365",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Evolution of LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "96962b6b-d959-4c4c-9078-4928a1e582e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x495ce6df0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Filter DataFrames for years starting from 2017\n",
    "start_year = 2019\n",
    "end_year = max(llm_bigram_df['year'].max(), llm_trigram_df['year'].max()) + 1\n",
    "\n",
    "years = list(range(start_year, end_year))\n",
    "\n",
    "# Initialize lists to store top 20 bigrams and trigrams for each year\n",
    "top_bigrams_by_year = {}\n",
    "top_trigrams_by_year = {}\n",
    "\n",
    "# Function to get top n bigrams or trigrams for a specific year\n",
    "def get_top_n_ngrams(df, year, n=20):\n",
    "    return df[df['year'] == year].nlargest(n, 'frequency')\n",
    "\n",
    "for year in years:\n",
    "    top_trigrams_by_year[year] = get_top_n_ngrams(llm_trigram_df, year)\n",
    "    top_bigrams_by_year[year] = get_top_n_ngrams(llm_bigram_df, year)\n",
    "\n",
    "# Create a Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Define the layout of the app\n",
    "app.layout = html.Div([\n",
    "    dcc.Graph(id='ngrams-graph'),\n",
    "    dcc.Slider(\n",
    "        id='year-slider',\n",
    "        min=start_year,\n",
    "        max=end_year,\n",
    "        step=1,\n",
    "        value=start_year,\n",
    "        marks={str(year): str(year) for year in years}\n",
    "    )\n",
    "])\n",
    "\n",
    "# Define a callback to update the graphs when the slider value changes\n",
    "@app.callback(\n",
    "    Output('ngrams-graph', 'figure'),\n",
    "    [Input('year-slider', 'value')]\n",
    ")\n",
    "def update_graphs(selected_year):\n",
    "    # Create a subplot with two columns for bigrams and trigrams\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Top 20 Trigrams\", \"Top 20 Bigrams\"))\n",
    "        # Add traces for top trigrams for the selected year\n",
    "    top_trigrams = top_trigrams_by_year[selected_year].sort_values(by='frequency')  # Sort by frequency\n",
    "    for i, row in top_trigrams.iterrows():\n",
    "        text = row['word'] if 'large' in row['word'].lower() else None  # Display text only if it contains \"large\"\n",
    "        marker_symbol = 'star-dot' if 'large' in row['word'].lower() else 'circle-open'  # Define marker symbol\n",
    "        legend_group = 'trigrams' if 'large' in row['word'].lower() else 'other'  # Group legends\n",
    "        fig.add_trace(go.Scatter(x=[row['word']], y=[row['frequency']], mode='lines+markers', name=text,\n",
    "                                 legendgroup=legend_group, showlegend=(legend_group == 'trigrams'),\n",
    "                                 marker=dict(\n",
    "                                     symbol=marker_symbol,\n",
    "                                     size=10  # Adjust the size of the marker as needed\n",
    "                                 )), row=1, col=1)\n",
    "    \n",
    "    # Add traces for top bigrams for the selected year\n",
    "    top_bigrams = top_bigrams_by_year[selected_year].sort_values(by='frequency')  # Sort by frequency\n",
    "    for i, row in top_bigrams.iterrows():\n",
    "        text = row['word'] if 'large' in row['word'].lower() else None  # Display text only if it contains \"large\"\n",
    "        marker_symbol = 'star-dot' if 'large' in row['word'].lower() else 'circle-open'  # Define marker symbol\n",
    "        legend_group = 'bigrams' if 'large' in row['word'].lower() else 'other'  # Group legends\n",
    "        fig.add_trace(go.Scatter(x=[row['word']], y=[row['frequency']], mode='lines+markers', name=text,\n",
    "                                 legendgroup=legend_group, showlegend=(legend_group == 'bigrams'),\n",
    "                                 marker=dict(\n",
    "                                     symbol=marker_symbol,\n",
    "                                     size=10,\n",
    "                                     # Adjust the size of the marker as needed\n",
    "                                 )), row=1, col=2)\n",
    "\n",
    "\n",
    "\n",
    "    fig.update_layout(title_text=f'Top 20 Trigrams and Bigrams in {selected_year}', showlegend=True)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff0637-4813-4bcd-ac6f-151886475d1e",
   "metadata": {},
   "source": [
    "### Individual Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e7f5e3bb-86bf-4ef1-be61-5e5c2fdff3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_full_form = {\n",
    "    'LLM': 'LLM',\n",
    "    'cs.AI': 'Artificial Intelligence',\n",
    "    'cs.CL': 'Computation and Language',\n",
    "    'cs.LG': 'Machine Learning',\n",
    "'cs.AR': 'Hardware Architecture',\n",
    "'cs.CC': 'Computational Complexity',\n",
    "'cs.CE': 'Computational Engineering, Finance, and Science',\n",
    "'cs.CG': 'Computational Geometry',\n",
    "'cs.CR': 'Cryptography and Security',\n",
    "'cs.CV': 'Computer Vision and Pattern Recognition',\n",
    "'cs.CY': 'Computers and Society',\n",
    "'cs.DB': 'Databases',\n",
    "'cs.DC': 'Distributed, Parallel, and Cluster Computing',\n",
    "'cs.DL': 'Digital Libraries',\n",
    "'cs.DM': 'Discrete Mathematics',\n",
    "'cs.DS': 'Data Structures and Algorithms',\n",
    "'cs.ET': 'Emerging Technologies',\n",
    "'cs.FL': 'Formal Languages and Automata Theory',\n",
    "'cs.GL': 'General Literature',\n",
    "'cs.GR': 'Graphics',\n",
    "'cs.GT': 'Computer Science and Game Theory',\n",
    "'cs.HC': 'Human-Computer Interaction',\n",
    "'cs.IR': 'Information Retrieval',\n",
    "'cs.IT': 'Information Theory',\n",
    "'cs.LO': 'Logic in Computer Science',\n",
    "'cs.MA': 'Multiagent Systems',\n",
    "'cs.MM': 'Multimedia',\n",
    "'cs.MS': 'Mathematical Software',\n",
    "'cs.NA': 'Numerical Analysis',\n",
    "'cs.NE': 'Neural and Evolutionary Computing',\n",
    "'cs.NI': 'Networking and Internet Architecture',\n",
    "'cs.OH': 'Other Computer Science',\n",
    "'cs.OS': 'Operating Systems',\n",
    "'cs.PF': 'Performance',\n",
    "'cs.PL': 'Programming Languages',\n",
    "'cs.RO': 'Robotics',\n",
    "'cs.SC': 'Symbolic Computation',\n",
    "'cs.SD': 'Sound',\n",
    "'cs.SE': 'Software Engineering',\n",
    "'cs.SI': 'Social and Information Networks',\n",
    "'cs.SY': 'Systems and Control',\n",
    "'stat.AP': 'Applications',\n",
    "'stat.CO': 'Computation',\n",
    "'stat.ME': 'Methodology',\n",
    "'stat.ML': 'Machine Learning',\n",
    "'stat.OT': 'Other Statistics',\n",
    "'stat.TH': 'Statistics Theory'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "182f7a3e-e9b0-463e-b59f-6606cb9e424d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_80.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample author name and format it\n",
    "author_string = 'Li Xiang'\n",
    "formatted_name = ' '.join(author_string.split())\n",
    "\n",
    "# Filter the dataset for the author\n",
    "author_each_publications = papers[papers['authors'].apply(lambda x: formatted_name in str(x))]\n",
    "llm_rows = author_each_publications['processed_titles_abstracts'].apply(check_terms_in_abstract_title)\n",
    "\n",
    "# Iterate over the rows and add 'LLM' category to the 'categories' column\n",
    "for idx, row in author_each_publications[llm_rows].iterrows():\n",
    "    author_each_publications.at[idx, 'categories'] = str(row['categories']) + ', LLM'\n",
    "\n",
    "# Split combined categories and count each subcategory individually\n",
    "author_each_publications['categories'] = author_each_publications['categories'].str.split()\n",
    "category_counts = author_each_publications.explode('categories').groupby(['year', 'categories']).size().reset_index(name='count')\n",
    "\n",
    "# Map categories to their full forms\n",
    "category_counts['categories_full'] = category_counts['categories'].map(categories_full_form)\n",
    "sorted_categories = category_counts.sort_values(by='count', ascending=False)['categories_full'].tolist()\n",
    "agg_category_counts = category_counts.groupby(['year', 'categories_full']).agg({'count': 'sum'}).reset_index()\n",
    "agg_category_counts = agg_category_counts[agg_category_counts['year'] >= 2014]\n",
    "# Plot different lines for different categories\n",
    "fig = px.line(agg_category_counts, x='year', y='count', color='categories_full', markers=True,\n",
    "              category_orders={'categories_full': sorted_categories},\n",
    "              title=f'Publication Count by {formatted_name} in Each Category Over Years')\n",
    "fig.update_layout(legend_title_text='Categories', yaxis_title='Publication Count')\n",
    "fig.for_each_trace(lambda t: t.update(line=dict(color='black', width=3)) if t.name == 'LLM' else t)\n",
    "# Hide legend items beyond the first 5 categories\n",
    "for i, data in enumerate(fig.data):\n",
    "    if i >= 15 and 'LLM' not in data.name:\n",
    "        data.showlegend = False\n",
    "\n",
    "# Always show 'LLM' in the legend\n",
    "fig.update_traces(showlegend=True, selector={'name': 'LLM'})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c700433e-792c-48f8-93a1-8a78ae0f4e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting author names: 100%|███████████████| 30/30 [00:00<00:00, 15167.44it/s]\n",
      "Filtering publications: 100%|███████████████████| 30/30 [00:14<00:00,  2.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_76.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "authors_all_publications = pd.DataFrame()\n",
    "# Assuming you have a DataFrame named 'papers'\n",
    "formatted_names = []\n",
    "\n",
    "for author_string in tqdm(llm_top_authors['author'], desc='Formatting author names'):\n",
    "    formatted_name = ' '.join(author_string.split())\n",
    "    formatted_names.append(formatted_name)\n",
    "\n",
    "# Loop through all formatted names and execute the code for each author\n",
    "for formatted_name in tqdm(formatted_names, desc='Filtering publications'):\n",
    "    # Filter the dataset for the author\n",
    "    publications = papers[papers['authors'].apply(lambda x: formatted_name in str(x))]\n",
    "    authors_all_publications = pd.concat([authors_all_publications, publications])\n",
    "\n",
    "llm_rows = authors_all_publications['processed_titles_abstracts'].apply(check_terms_in_abstract_title)\n",
    "\n",
    "# Iterate over the rows and add 'LLM' category to the 'categories' column\n",
    "for idx, row in authors_all_publications[llm_rows].iterrows():\n",
    "    if row['categories']:\n",
    "        if 'cs.CL' in str(row['categories']):\n",
    "            authors_all_publications.at[idx, 'categories'] = str(row['categories']) + ', LLM'\n",
    "    else:\n",
    "        authors_all_publications.at[idx, 'categories'] = str(row['categories'])\n",
    "\n",
    "# Split combined categories and count each subcategory individually\n",
    "authors_all_publications['categories'] = authors_all_publications['categories'].str.split()\n",
    "category_counts = authors_all_publications.explode('categories').groupby(['year', 'categories']).size().reset_index(name='count')\n",
    "\n",
    "# Map categories to their full forms\n",
    "category_counts['categories_full'] = category_counts['categories'].map(categories_full_form)\n",
    "sorted_categories = category_counts.sort_values(by='count', ascending=False)['categories_full'].tolist()\n",
    "agg_category_counts = category_counts.groupby(['year', 'categories_full']).agg({'count': 'sum'}).reset_index()\n",
    "agg_category_counts = agg_category_counts[agg_category_counts['year'] >= 2014]\n",
    "\n",
    "# Plot different lines for different categories\n",
    "fig = px.line(agg_category_counts, x='year', y='count', color='categories_full', markers=True,\n",
    "              category_orders={'categories_full': sorted_categories},\n",
    "              title=f'Publication Count by Top LLM Authors in Each Category Over Years')\n",
    "\n",
    "fig.update_layout(legend_title_text='Categories',yaxis_title='Publication Count')\n",
    "fig.for_each_trace(lambda t: t.update(line=dict(color='black', width=3)) if t.name == 'LLM' else t)\n",
    "# Hide legend items beyond the first 5 categories\n",
    "for i, data in enumerate(fig.data):\n",
    "    if i >= 15 and 'LLM' not in data.name:\n",
    "        data.showlegend = False\n",
    "\n",
    "# Always show 'LLM' in the legend\n",
    "fig.update_traces(showlegend=True, selector={'name': 'LLM'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c0c24da5-dafa-4ca3-8cef-482110c9e956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting author names: 100%|███████████████| 22/22 [00:00<00:00, 90200.09it/s]\n",
      "Filtering publications: 100%|███████████████████| 22/22 [00:06<00:00,  3.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_77.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "authors_all_publications = pd.DataFrame()\n",
    "# Assuming you have a DataFrame named 'papers'\n",
    "formatted_names = []\n",
    "for author_string in tqdm(senior_authors_df['author'], desc='Formatting author names'):\n",
    "    formatted_name = ' '.join(author_string.split())\n",
    "    formatted_names.append(formatted_name)\n",
    "\n",
    "# Loop through all formatted names and execute the code for each author\n",
    "for formatted_name in tqdm(formatted_names, desc='Filtering publications'):\n",
    "    # Filter the dataset for the author\n",
    "    publications = papers[papers['authors'].apply(lambda x: formatted_name in str(x))]\n",
    "    authors_all_publications = pd.concat([authors_all_publications, publications])\n",
    "\n",
    "\n",
    "llm_rows = authors_all_publications['processed_titles_abstracts'].apply(check_terms_in_abstract_title)\n",
    "\n",
    "# Iterate over the rows and add 'LLM' category to the 'categories' column\n",
    "for idx, row in authors_all_publications[llm_rows].iterrows():\n",
    "    if row['categories']:\n",
    "        authors_all_publications.at[idx, 'categories'] = str(row['categories']) + ', LLM'\n",
    "    else:\n",
    "        authors_all_publications.at[idx, 'categories'] = str(row['categories'])\n",
    "\n",
    "\n",
    "# Split combined categories and count each subcategory individually\n",
    "authors_all_publications['categories'] = authors_all_publications['categories'].str.split()\n",
    "category_counts = authors_all_publications.explode('categories').groupby(['year', 'categories']).size().reset_index(name='count')\n",
    "\n",
    "# Map categories to their full forms\n",
    "category_counts['categories_full'] = category_counts['categories'].map(categories_full_form)\n",
    "# Get the top 5 categories based on count\n",
    "top_categories = category_counts.groupby('categories_full')['count'].sum().sort_values(ascending=False).head(5).index\n",
    "\n",
    "# Filter the data to include only the top 5 categories\n",
    "category_counts_top5 = category_counts[category_counts['categories_full'].isin(top_categories)]\n",
    "\n",
    "# Sort categories for better visualization in the legend\n",
    "sorted_categories = category_counts_top5.sort_values(by='count', ascending=False)['categories_full'].tolist()\n",
    "agg_category_counts = category_counts.groupby(['year', 'categories_full']).agg({'count': 'sum'}).reset_index()\n",
    "agg_category_counts = agg_category_counts[agg_category_counts['year'] >= 2014]\n",
    "# Plot all lines for different categories\n",
    "fig = px.line(agg_category_counts, x='year', y='count', color='categories_full', markers=True,\n",
    "              category_orders={'categories_full': sorted_categories},\n",
    "              title=f'Publication Count by Top LLM Senior Authors in Each Category Over Years')\n",
    "\n",
    "fig.update_layout(legend_title_text='Categories', yaxis_title='Publication Count')\n",
    "fig.for_each_trace(lambda t: t.update(line=dict(color='black', width=3)) if t.name == 'LLM' else t)\n",
    "for i, data in enumerate(fig.data):\n",
    "    if i >= 15 and 'LLM' not in data.name:\n",
    "        data.showlegend = False\n",
    "fig.update_traces(showlegend=True, selector={'name': 'LLM'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f41af608-beb2-4e4a-80c5-2e3acc3d24eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting author names: 100%|█████████████████| 8/8 [00:00<00:00, 78398.21it/s]\n",
      "Filtering publications: 100%|█████████████████████| 8/8 [00:02<00:00,  3.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_78.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "authors_all_publications = pd.DataFrame()\n",
    "# Assuming you have a DataFrame named 'papers'\n",
    "formatted_names = []\n",
    "for author_string in tqdm(junior_authors_df['author'], desc='Formatting author names'):\n",
    "    formatted_name = ' '.join(author_string.split())\n",
    "    formatted_names.append(formatted_name)\n",
    "\n",
    "# Loop through all formatted names and execute the code for each author\n",
    "for formatted_name in tqdm(formatted_names, desc='Filtering publications'):\n",
    "    # Filter the dataset for the author\n",
    "    publications = papers[papers['authors'].apply(lambda x: formatted_name in str(x))]\n",
    "    authors_all_publications = pd.concat([authors_all_publications, publications])\n",
    "\n",
    "\n",
    "llm_rows = authors_all_publications['processed_titles_abstracts'].apply(check_terms_in_abstract_title)\n",
    "\n",
    "# Iterate over the rows and add 'LLM' category to the 'categories' column\n",
    "for idx, row in authors_all_publications[llm_rows].iterrows():\n",
    "    if row['categories']:\n",
    "        authors_all_publications.at[idx, 'categories'] = str(row['categories']) + ', LLM'\n",
    "    else:\n",
    "        authors_all_publications.at[idx, 'categories'] = str(row['categories'])\n",
    "\n",
    "\n",
    "# Split combined categories and count each subcategory individually\n",
    "authors_all_publications['categories'] = authors_all_publications['categories'].str.split()\n",
    "category_counts = authors_all_publications.explode('categories').groupby(['year', 'categories']).size().reset_index(name='count')\n",
    "\n",
    "# Map categories to their full forms\n",
    "category_counts['categories_full'] = category_counts['categories'].map(categories_full_form)\n",
    "# Get the top 5 categories based on count\n",
    "top_categories = category_counts.groupby('categories_full')['count'].sum().sort_values(ascending=False).head(5).index\n",
    "\n",
    "# Filter the data to include only the top 5 categories\n",
    "category_counts_top5 = category_counts[category_counts['categories_full'].isin(top_categories)]\n",
    "\n",
    "# Sort categories for better visualization in the legend\n",
    "sorted_categories = category_counts_top5.sort_values(by='count', ascending=False)['categories_full'].tolist()\n",
    "agg_category_counts = category_counts.groupby(['year', 'categories_full']).agg({'count': 'sum'}).reset_index()\n",
    "agg_category_counts = agg_category_counts[agg_category_counts['year'] >= 2014]\n",
    "# Plot all lines for different categories\n",
    "fig = px.line(agg_category_counts, x='year', y='count', color='categories_full', markers=True,\n",
    "              category_orders={'categories_full': sorted_categories},\n",
    "              title=f'Publication Count by Top LLM Junior Authors in Each Category Over Years')\n",
    "\n",
    "fig.update_layout(legend_title_text='Categories',yaxis_title='Publication Count')\n",
    "fig.for_each_trace(lambda t: t.update(line=dict(color='black', width=3)) if t.name == 'LLM' else t)\n",
    "for i, data in enumerate(fig.data):\n",
    "    if i >= 15 and 'LLM' not in data.name:\n",
    "        data.showlegend = False\n",
    "fig.update_traces(showlegend=True, selector={'name': 'LLM'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e01e5616-8afa-400f-8c70-c48455735014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting author names: 100%|███████████████| 30/30 [00:00<00:00, 70611.18it/s]\n",
      "Filtering publications: 100%|███████████████████| 30/30 [00:22<00:00,  1.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_79.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "authors_all_publications = pd.DataFrame()\n",
    "# Assuming you have a DataFrame named 'papers'\n",
    "formatted_names = []\n",
    "for author_string in tqdm(papers_by_authors['authors'], desc='Formatting author names'):\n",
    "    formatted_name = ' '.join(author_string.split())\n",
    "    formatted_names.append(formatted_name)\n",
    "\n",
    "# Loop through all formatted names and execute the code for each author\n",
    "for formatted_name in tqdm(formatted_names, desc='Filtering publications'):\n",
    "    # Filter the dataset for the author\n",
    "    publications = papers[papers['authors'].apply(lambda x: formatted_name in str(x))]\n",
    "    authors_all_publications = pd.concat([authors_all_publications, publications])\n",
    "\n",
    "\n",
    "llm_rows = authors_all_publications['processed_titles_abstracts'].apply(check_terms_in_abstract_title)\n",
    "\n",
    "# Iterate over the rows and add 'LLM' category to the 'categories' column\n",
    "for idx, row in authors_all_publications[llm_rows].iterrows():\n",
    "    if row['categories']:\n",
    "        authors_all_publications.at[idx, 'categories'] = str(row['categories']) + ', LLM'\n",
    "    else:\n",
    "        authors_all_publications.at[idx, 'categories'] = str(row['categories'])\n",
    "\n",
    "\n",
    "# Split combined categories and count each subcategory individually\n",
    "authors_all_publications['categories'] = authors_all_publications['categories'].str.split()\n",
    "category_counts = authors_all_publications.explode('categories').groupby(['year', 'categories']).size().reset_index(name='count')\n",
    "\n",
    "# Map categories to their full forms\n",
    "category_counts['categories_full'] = category_counts['categories'].map(categories_full_form)\n",
    "# Get the top 5 categories based on count\n",
    "top_categories = category_counts.groupby('categories_full')['count'].sum().sort_values(ascending=False).head(5).index\n",
    "\n",
    "# Filter the data to include only the top 5 categories\n",
    "category_counts_top5 = category_counts[category_counts['categories_full'].isin(top_categories)]\n",
    "\n",
    "# Sort categories for better visualization in the legend\n",
    "sorted_categories = category_counts_top5.sort_values(by='count', ascending=False)['categories_full'].tolist()\n",
    "agg_category_counts = category_counts.groupby(['year', 'categories_full']).agg({'count': 'sum'}).reset_index()\n",
    "agg_category_counts = agg_category_counts[agg_category_counts['year'] >= 2014]\n",
    "# Plot all lines for different categories\n",
    "fig = px.line(agg_category_counts, x='year', y='count', color='categories_full', markers=True,\n",
    "              category_orders={'categories_full': sorted_categories},\n",
    "              title=f'Publication Count by Top Preprint Platform Authors in Each Category Over Years')\n",
    "\n",
    "fig.update_layout(legend_title_text='Categories', yaxis_title='Publication Count')\n",
    "\n",
    "fig.for_each_trace(lambda t: t.update(line=dict(color='black', width=3)) if t.name == 'LLM' else t)\n",
    "# Hide legend items beyond the first 5 categories\n",
    "for i, data in enumerate(fig.data):\n",
    "    if i >= 15 and 'LLM' not in data.name:\n",
    "        data.showlegend = False\n",
    "\n",
    "# Always show 'LLM' in the legend\n",
    "fig.update_traces(showlegend=True, selector={'name': 'LLM'})\n",
    "\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bd8803-02ad-4686-a233-3093409ae3a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
